{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Deep Learning\n",
    "## Project: Build a Digit Recognition Program\n",
    "\n",
    "In this notebook, a template is provided for you to implement your functionality in stages which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission, if necessary. Sections that begin with **'Implementation'** in the header indicate where you should begin your implementation for your project. Note that some sections of implementation are optional, and will be marked with **'Optional'** in the header.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "----\n",
    "## Step 1: Design and Test a Model Architecture\n",
    "Design and implement a deep learning model that learns to recognize sequences of digits. Train the model using synthetic data generated by concatenating character images from [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) or [MNIST](http://yann.lecun.com/exdb/mnist/). To produce a synthetic sequence of digits for testing, you can for example limit yourself to sequences up to five digits, and use five classifiers on top of your deep network. You would have to incorporate an additional ‘blank’ character to account for shorter number sequences.\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "- Your model can be derived from a deep neural net or a convolutional network.\n",
    "- You could experiment sharing or not the weights between the softmax classifiers.\n",
    "- You can also use a recurrent network in your deep neural net to replace the classification layers and directly emit the sequence of digits one-at-a-time.\n",
    "\n",
    "You can use ** Keras ** to implement your model. Read more at [keras.io](https://keras.io/).\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf). ([video](https://www.youtube.com/watch?v=vGPI_JvLoN0)). You are not expected to model your architecture precisely using this model nor get the same performance levels, but this is more to show an exampe of an approach used to solve this particular problem. We encourage you to try out different architectures for yourself and see what works best for you. Here is a useful [forum post](https://discussions.udacity.com/t/goodfellow-et-al-2013-architecture/202363) discussing the architecture as described in the paper and here is [another one](https://discussions.udacity.com/t/what-loss-function-to-use-for-multi-digit-svhn-training/176897) discussing the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### cnn_trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import gc\n",
    "import math\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from data_loader import MNISTLoader, SVHNLoader\n",
    "from image_process import ImageProcess\n",
    "\n",
    "_DEBUG = True\n",
    "\n",
    "\n",
    "def _log(message, end='\\r\\n'):\n",
    "    if _DEBUG:\n",
    "        print(message, end=end)\n",
    "\n",
    "\n",
    "class CNNTrainer:\n",
    "\n",
    "    train_name = 'convolution_neural_networks_train'\n",
    "    summary_dirname = None\n",
    "    ckpt_saver = None\n",
    "    ckpt_fname = None\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        return\n",
    "\n",
    "    def weight_variable(self, shape, name=None, kstddev = None):\n",
    "        \"\"\"\n",
    "        Initialize weight variables\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        shape : list\n",
    "            weight variable's shape\n",
    "        name : str\n",
    "            tensorflow graph's name\n",
    "        kstddev: int\n",
    "            if you want to customize stddev up to image size, pass the size using this parameter\n",
    "            normally you can use image's W * H * depth or labels' distinct encoding\n",
    "            from https://arxiv.org/pdf/1502.01852v1.pdf\n",
    "\n",
    "\n",
    "        Returns\n",
    "        ------\n",
    "        tf.Variable\n",
    "        \"\"\"\n",
    "\n",
    "        name = '%s_w' % name if not name else None\n",
    "        stddev = None if kstddev is None else math.sqrt(2.0 / kstddev)\n",
    "\n",
    "        return tf.Variable(tf.truncated_normal(shape, stddev=0.1),\n",
    "                           dtype=tf.float32,\n",
    "                           name=name)\n",
    "\n",
    "    def bias_variable(self, shape, name=None):\n",
    "        name = '%s_b' % name if not name else None\n",
    "\n",
    "        return tf.Variable(tf.zeros(shape),\n",
    "                           dtype=tf.float32,\n",
    "                           name=name)\n",
    "\n",
    "    def conv2d(self, x, W, strides=[1,1,1,1], padding='SAME'):\n",
    "\n",
    "        strides = strides\n",
    "        padding = padding\n",
    "\n",
    "        return tf.nn.conv2d(x, W,\n",
    "                            strides=strides,\n",
    "                            padding=padding)\n",
    "\n",
    "    def max_pool_2x2(self, x):\n",
    "        return tf.nn.max_pool(x,\n",
    "                              ksize=[1, 2, 2, 1],\n",
    "                              strides=[1, 2, 2, 1],\n",
    "                              padding='SAME')\n",
    "\n",
    "    # def get_conv2d(name, data, patch, d_in, d_out, stride, pooling=None):\n",
    "    #     weights = tf.Variable(tf.truncated_normal([patch, patch, d_in, d_out],\n",
    "    #                                               stddev=get_conv2d_weights_init_stddev(img_w, img_h, d_in)),\n",
    "    #                           name=str('%s_w' % name))\n",
    "\n",
    "    #     biases = tf.Variable(tf.zeros([d_out]),\n",
    "    #                          name=str('%s_b' % name))\n",
    "\n",
    "    #     layer = tf.nn.relu(tf.nn.conv2d(data, weights, stride, padding='SAME') + biases)\n",
    "\n",
    "    #     if pooling is not None:\n",
    "    #         layer = tf.nn.max_pool(layer, pooling, pooling, padding='SAME')\n",
    "\n",
    "    #     return weights, biases, layer\n",
    "\n",
    "    # def get_conv2d_weights_init_stddev(w, h, d_in):\n",
    "    #     # from https://arxiv.org/pdf/1502.01852v1.pdf\n",
    "    #     return math.sqrt(2.0 / (w*h*d_in))\n",
    "\n",
    "    # def get_fc(name, data, depth, relu=True):\n",
    "    #     inbound = int(data.get_shape()[1])\n",
    "    #     weights = tf.Variable(tf.truncated_normal([inbound, depth], stddev=math.sqrt(2.0 / inbound), name=str('%s_w' % name)))\n",
    "    #     biases = tf.Variable(tf.zeros([depth]), name=str('%s_b' % name))\n",
    "    #     layer = tf.matmul(data, weights) + biases\n",
    "    #     if relu is True:\n",
    "    #         layer = tf.nn.relu(layer)\n",
    "    #     return weights, biases, layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class MNISTTrainer(CNNTrainer):\n",
    "\n",
    "    tf_x = None\n",
    "    tf_y_ = None\n",
    "\n",
    "    tf_keep_prob = None\n",
    "    tf_l2_beta = None\n",
    "\n",
    "    train_dataset = None\n",
    "    test_dataset = None\n",
    "\n",
    "    tf_optimizer = None\n",
    "    tf_accuracy = None\n",
    "    tf_loss = None\n",
    "\n",
    "    raw_image_shape = None\n",
    "    image_shape = None\n",
    "    label_shape = None\n",
    "\n",
    "    is_model_initialized = False\n",
    "\n",
    "    tf_debug1 = None\n",
    "    tf_debug2 = None\n",
    "    tf_debug3 = None\n",
    "    tf_debug4 = None\n",
    "\n",
    "    seed = 42\n",
    "    pred_value = None\n",
    "\n",
    "    def __init__(self, image_shape=[None, 32, 32, 3], label_shape=[None, 10], train_name=None):\n",
    "\n",
    "        # set image, label shape\n",
    "        self.image_shape = image_shape\n",
    "        self.label_shape = label_shape\n",
    "        self.raw_image_shape = self.image_shape if image_shape[3] != 1 else image_shape[0:3]\n",
    "\n",
    "        _log('input shape must be ', end='')\n",
    "        _log(self.raw_image_shape)\n",
    "\n",
    "        # set tf variables for input, labels and hyper-parameters\n",
    "        self.tf_x = tf.placeholder(tf.float32, self.raw_image_shape)\n",
    "        self.tf_y_ = tf.placeholder(tf.float32, self.label_shape)\n",
    "\n",
    "        self.tf_learning_rate = tf.placeholder(tf.float32)\n",
    "        self.tf_l2_beta = tf.placeholder(tf.float32)\n",
    "\n",
    "        self.tf_keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "        # set this trainer name\n",
    "        self.train_name = train_name if train_name else self.train_name\n",
    "        self.ckpt_fname = './ckpt/%s.ckpt' % self.train_name\n",
    "        self.summary_dirname = './summary/%s/' % self.train_name\n",
    "\n",
    "        return\n",
    "\n",
    "    def set_model(self):\n",
    "        self.is_model_initialized = True\n",
    "\n",
    "        x_input = tf.reshape(self.tf_x, [-1] + self.image_shape[1:4])\n",
    "\n",
    "        # convolution vector definition\n",
    "        w_conv1 = self.weight_variable([5, 5, 1, 16], name='conv1')\n",
    "        b_conv1 = self.bias_variable([16], name='conv1')\n",
    "\n",
    "        w_conv2 = self.weight_variable([5, 5, 16, 32], name='conv2')\n",
    "        b_conv2 = self.bias_variable([32], name='conv2')\n",
    "\n",
    "        w_conv3 = self.weight_variable([5, 5, 32, 64], name='conv3')\n",
    "        b_conv3 = self.bias_variable([64], name='conv3')\n",
    "\n",
    "        w_conv4 = self.weight_variable([5, 5, 64, 128], name='conv4')\n",
    "        b_conv4 = self.bias_variable([128], name='conv4')\n",
    "\n",
    "        w_fc1 = self.weight_variable([4 * 4 * 128, 256], name='fc1')\n",
    "        b_fc1 = self.bias_variable([256], name='fc1')\n",
    "\n",
    "        w_fc2 = self.weight_variable([256, 128], name='fc2')\n",
    "        b_fc2 = self.bias_variable([128], name='fc2')\n",
    "\n",
    "        # weight & bias matrix depends on features\n",
    "        w_fc2_len = self.weight_variable([128, 10], name='fc2_len')\n",
    "        b_fc2_len = self.bias_variable([10], name='fc2_len')\n",
    "\n",
    "        w_fc2_d1 = self.weight_variable([128, 10], name='fc2_d1')\n",
    "        b_fc2_d1 = self.bias_variable([10], name='fc2_d1')\n",
    "\n",
    "        w_fc2_d2 = self.weight_variable([128, 10], name='fc2_d2')\n",
    "        b_fc2_d2 = self.bias_variable([10], name='fc2_d2')\n",
    "\n",
    "        w_fc2_d3 = self.weight_variable([128, 10], name='fc2_d3')\n",
    "        b_fc2_d3 = self.bias_variable([10], name='fc2_d3')\n",
    "\n",
    "        w_fc2_d4 = self.weight_variable([128, 10], name='fc2_d4')\n",
    "        b_fc2_d4 = self.bias_variable([10], name='fc2_d4')\n",
    "\n",
    "        w_fc2_d5 = self.weight_variable([128, 10], name='fc2_d5')\n",
    "        b_fc2_d5 = self.bias_variable([10], name='fc2_d5')\n",
    "\n",
    "        w_fc2_d6 = self.weight_variable([128, 10], name='fc2_d6')\n",
    "        b_fc2_d6 = self.bias_variable([10], name='fc2_d6')\n",
    "\n",
    "        # set up saver for continuous learning\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/train/Saver\n",
    "        param_lst = [w_conv1, w_conv2, w_conv3, w_conv4, w_fc1, w_fc2,]\n",
    "        param_lst += [b_conv1, b_conv2, b_conv3, b_conv4, b_fc1, b_fc2,]\n",
    "        param_lst += [w_fc2_len, w_fc2_d1, w_fc2_d2, w_fc2_d3, w_fc2_d4, w_fc2_d5, w_fc2_d6, ]\n",
    "        param_lst += [b_fc2_len, b_fc2_d1, b_fc2_d2, b_fc2_d3, b_fc2_d4, b_fc2_d5, b_fc2_d6, ]\n",
    "\n",
    "        self.ckpt_saver = tf.train.Saver(param_lst)\n",
    "\n",
    "        # convolution layer\n",
    "        with tf.name_scope('hidden_layer1') as hl_scope1:\n",
    "            h_conv1 = tf.nn.relu(self.conv2d(x_input, w_conv1) + b_conv1)\n",
    "            h_pool1 = self.max_pool_2x2(h_conv1)\n",
    "\n",
    "        with tf.name_scope('hidden_layer2') as hl_scope2:\n",
    "            h_conv2 = tf.nn.relu(self.conv2d(h_pool1, w_conv2) + b_conv2)\n",
    "            h_pool2 = self.max_pool_2x2(h_conv2)\n",
    "\n",
    "        with tf.name_scope('hidden_layer3') as hl_scope3:\n",
    "            h_conv3 = tf.nn.relu(self.conv2d(h_pool2, w_conv3) + b_conv3)\n",
    "            h_pool3 = self.max_pool_2x2(h_conv3)\n",
    "\n",
    "        with tf.name_scope('hidden_layer4') as hl_scope4:\n",
    "            h_conv4 = tf.nn.relu(self.conv2d(h_pool3, w_conv4) + b_conv4)\n",
    "            h_pool4 = self.max_pool_2x2(h_conv4)\n",
    "\n",
    "        # fully connected layer\n",
    "        with tf.name_scope('fully_connected_layer1') as fc_scope1:\n",
    "            shape  = h_pool4.get_shape().as_list()\n",
    "            h_pool4_flat = tf.reshape(h_pool4, [-1, shape[1] * shape[2] * shape[3]])\n",
    "\n",
    "            h_pool4_flat_dropout = tf.nn.dropout(h_pool4_flat, self.tf_keep_prob, seed=self.seed)\n",
    "            h_fc1 = tf.nn.relu(tf.matmul(h_pool4_flat_dropout, w_fc1) + b_fc1)\n",
    "\n",
    "        # dropout\n",
    "        with tf.name_scope('fully_connected_layer2') as fc_scope2:\n",
    "            h_fc1_dropout = tf.nn.dropout(h_fc1, self.tf_keep_prob, seed=self.seed)\n",
    "            h_fc2 = tf.nn.relu(tf.matmul(h_fc1_dropout, w_fc2)+b_fc2)\n",
    "\n",
    "        # readout layer\n",
    "        with tf.name_scope('readout_layer') as ro_scope:\n",
    "            pred_r_len = tf.matmul(h_fc2, w_fc2_len) + b_fc2_len\n",
    "            pred_len = tf.reshape(pred_r_len, [-1,10])\n",
    "\n",
    "            pred_r_d1 = tf.matmul(h_fc2, w_fc2_d1) + b_fc2_d1\n",
    "            pred_d1 = tf.reshape(pred_r_d1, [-1,10])\n",
    "\n",
    "            pred_r_d2 = tf.matmul(h_fc2, w_fc2_d2) + b_fc2_d2\n",
    "            pred_d2 = tf.reshape(pred_r_d2, [-1,10])\n",
    "\n",
    "            pred_r_d3 = tf.matmul(h_fc2, w_fc2_d3) + b_fc2_d3\n",
    "            pred_d3 = tf.reshape(pred_r_d3, [-1,10])\n",
    "\n",
    "            pred_r_d4 = tf.matmul(h_fc2, w_fc2_d4) + b_fc2_d4\n",
    "            pred_d4 = tf.reshape(pred_r_d4, [-1,10])\n",
    "\n",
    "            pred_r_d5 = tf.matmul(h_fc2, w_fc2_d5) + b_fc2_d5\n",
    "            pred_d5 = tf.reshape(pred_r_d5, [-1,10])\n",
    "\n",
    "            pred_r_d6 = tf.matmul(h_fc2, w_fc2_d6) + b_fc2_d6\n",
    "            pred_d6 = tf.reshape(pred_r_d6, [-1,10])\n",
    "\n",
    "        # loss calculation\n",
    "        with tf.name_scope('loss_calculation') as lc_scope:\n",
    "            softmax_len = tf.nn.softmax_cross_entropy_with_logits(labels=tf.reshape(self.tf_y_, (-1,7,10))[:,0,:],\n",
    "                                                                  logits=pred_len)\n",
    "            softmax_d1 = tf.nn.softmax_cross_entropy_with_logits(labels=tf.reshape(self.tf_y_, (-1,7,10))[:,1,:],\n",
    "                                                                  logits=pred_d1)\n",
    "            softmax_d2 = tf.nn.softmax_cross_entropy_with_logits(labels=tf.reshape(self.tf_y_, (-1,7,10))[:,2,:],\n",
    "                                                                  logits=pred_d2)\n",
    "            softmax_d3 = tf.nn.softmax_cross_entropy_with_logits(labels=tf.reshape(self.tf_y_, (-1,7,10))[:,3,:],\n",
    "                                                                  logits=pred_d3)\n",
    "            softmax_d4 = tf.nn.softmax_cross_entropy_with_logits(labels=tf.reshape(self.tf_y_, (-1,7,10))[:,4,:],\n",
    "                                                                  logits=pred_d4)\n",
    "            softmax_d5 = tf.nn.softmax_cross_entropy_with_logits(labels=tf.reshape(self.tf_y_, (-1,7,10))[:,5,:],\n",
    "                                                                  logits=pred_d5)\n",
    "            softmax_d6 = tf.nn.softmax_cross_entropy_with_logits(labels=tf.reshape(self.tf_y_, (-1,7,10))[:,6,:],\n",
    "                                                                  logits=pred_d6)\n",
    "\n",
    "            regularization = tf.nn.l2_loss(w_fc1) + tf.nn.l2_loss(b_fc1)\n",
    "            self.tf_loss = self.tf_l2_beta * regularization\n",
    "            self.tf_loss += tf.reduce_mean(softmax_len)\n",
    "            self.tf_loss += tf.reduce_mean(softmax_d1)\n",
    "            self.tf_loss += tf.reduce_mean(softmax_d2)\n",
    "            self.tf_loss += tf.reduce_mean(softmax_d3)\n",
    "            self.tf_loss += tf.reduce_mean(softmax_d4)\n",
    "            self.tf_loss += tf.reduce_mean(softmax_d5)\n",
    "            # self.tf_loss += tf.reduce_mean(softmax_d6)\n",
    "\n",
    "            tf.summary.scalar('loss', self.tf_loss)\n",
    "\n",
    "        # loss optimizer\n",
    "        with tf.name_scope('training') as tr_scope:\n",
    "            self.tf_optimizer = tf.train.AdamOptimizer(learning_rate=self.tf_learning_rate).minimize(self.tf_loss)\n",
    "\n",
    "        # accuracy calculation\n",
    "        with tf.name_scope('accuracy_calculation') as acc_scope:\n",
    "            pred_combined = tf.stack([pred_len, pred_d1, pred_d2, pred_d3, pred_d4, pred_d5, pred_d6], axis=1)\n",
    "            predict = tf.reshape(pred_combined, (-1, 7, 10))\n",
    "            is_correct_pred = tf.equal(\n",
    "                tf.argmax(predict, 2), tf.argmax(tf.reshape(self.tf_y_, (-1,7,10)), 2))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(is_correct_pred, tf.float32))\n",
    "            tf.summary.scalar('accuracy', self.tf_accuracy)\n",
    "\n",
    "            self.pred_value = tf.argmax(predict, 2)\n",
    "\n",
    "\n",
    "    def train(self, for_training=True):\n",
    "        if not self.is_model_initialized:\n",
    "            raise AssertionError('you must initilize model using set_model function')\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            # generate tensorflow summary merged\n",
    "            merged = tf.summary.merge_all()\n",
    "            train_writer = tf.summary.FileWriter(self.summary_dirname, sess.graph)\n",
    "\n",
    "            # Batching data\n",
    "            batch_size = 50\n",
    "            train_size = self.train_dataset[0].shape[0]\n",
    "\n",
    "            # hyper-parameters\n",
    "            learning_rate = 3.1e-4\n",
    "            l2_beta = 16e-4\n",
    "            keep_prob = 0.5\n",
    "\n",
    "            feed_train = None\n",
    "            feed_accu = None\n",
    "            feed_test = None\n",
    "\n",
    "            if for_training:\n",
    "                _log('we\\'re about to training using %d trainset...' % self.train_dataset[0].shape[0])\n",
    "                _log('trainset size : {:4d}'.format(train_size))\n",
    "                _log('batch    size : {:4d}'.format(batch_size))\n",
    "\n",
    "                _log('. : 1 training epoch')\n",
    "\n",
    "                for epoch in range(200):\n",
    "\n",
    "                    # Shuffling the train sets\n",
    "                    indices = np.random.permutation(range(self.train_dataset[0].shape[0]))\n",
    "                    for i, _ in enumerate(self.train_dataset):\n",
    "                        self.train_dataset[i] = self.train_dataset[i][indices]\n",
    "\n",
    "                    # batch_ training\n",
    "                    for batch_step in range(0, train_size, batch_size):\n",
    "\n",
    "                        batch = [\n",
    "                            self.train_dataset[0][batch_step:batch_step+batch_size],\n",
    "                            self.train_dataset[4][batch_step:batch_step+batch_size],\n",
    "                            self.train_dataset[1][batch_step:batch_step+batch_size]]\n",
    "\n",
    "                        # Check batch images for the training\n",
    "                        if False:\n",
    "                            fig = plt.figure(figsize=(12, 1), dpi=80)\n",
    "\n",
    "                            for i in range(12):\n",
    "                                plt.subplot(1, 12, i+1)\n",
    "                                plt.title(batch[2][i])\n",
    "                                plt.imshow(batch[0][i,:,:].reshape(64, 64),\n",
    "                                           interpolation='nearest',\n",
    "                                           cmap='Grey')\n",
    "                                plt.tight_layout()\n",
    "\n",
    "                            plt.show()\n",
    "\n",
    "                        feed_train ={self.tf_x: batch[0],\n",
    "                                     self.tf_y_: batch[1],\n",
    "                                     self.tf_learning_rate: learning_rate,\n",
    "                                     self.tf_l2_beta: l2_beta,\n",
    "                                     self.tf_keep_prob: keep_prob}\n",
    "\n",
    "                        feed_accu ={self.tf_x: batch[0],\n",
    "                                     self.tf_y_: batch[1],\n",
    "                                     self.tf_learning_rate: learning_rate,\n",
    "                                     self.tf_l2_beta: l2_beta,\n",
    "                                     self.tf_keep_prob: 1.0}\n",
    "\n",
    "                        # Do training\n",
    "                        self.tf_optimizer.run(feed_dict=feed_train)\n",
    "\n",
    "                    # tensorflow logging for tensorboard\n",
    "                    _summaries = sess.run(merged, feed_dict=feed_train)\n",
    "                    train_writer.add_summary(_summaries, epoch)\n",
    "\n",
    "                    # save model weights and biases\n",
    "                    self.ckpt_saver.save(sess, self.ckpt_fname)\n",
    "\n",
    "                    # logging loss and accuracy\n",
    "                    print(\".\", end='')\n",
    "                    if not epoch % 20:\n",
    "                        _loss, _train_accuracy = sess.run([self.tf_loss, self.tf_accuracy],\n",
    "                                                          feed_dict=feed_accu)\n",
    "\n",
    "                        print('')\n",
    "                        print(\"epoch {:4d} -> loss : {:05.2f} / training_accuracy: {:05.2f}\".format(\n",
    "                            epoch, _loss, _train_accuracy))\n",
    "\n",
    "            self.ckpt_saver.restore(sess, self.ckpt_fname)\n",
    "\n",
    "            feed_test = {self.tf_x: self.test_dataset[0],\n",
    "                         self.tf_y_: self.test_dataset[4],\n",
    "                         self.tf_learning_rate: learning_rate,\n",
    "                         self.tf_l2_beta: l2_beta,\n",
    "                         self.tf_keep_prob: 1.0}\n",
    "\n",
    "            print('testing accuracy {:05.2f}'.format(self.tf_accuracy.eval(feed_dict=feed_test)))\n",
    "        return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def train_for_mnist_synthetic():\n",
    "    loader = MNISTLoader()\n",
    "    loader.init_data()\n",
    "\n",
    "    trainer = MNISTTrainer([None, 64, 64, 1], [None, 70], train_name='mnist_synthetic')\n",
    "\n",
    "    _log('data loading...', end='\\r\\n')\n",
    "\n",
    "    trainer.train_dataset = list(loader.get_mixed_data(\"training\"))\n",
    "    trainer.test_dataset = list(loader.get_mixed_data(\"testing\"))\n",
    "\n",
    "    train_L = np.c_[trainer.train_dataset[3]+1, trainer.train_dataset[2]]\n",
    "    train_L_1hot = np.array([[loader.label_to_onehot(digit)] for digit in train_L.T])\n",
    "    train_L_1hot = np.transpose(train_L_1hot, (1,2,0,3))\n",
    "    train_L_1hot = train_L_1hot.reshape((-1, 7 * 10))\n",
    "\n",
    "    test_L = np.c_[trainer.test_dataset[3]+1, trainer.test_dataset[2]]\n",
    "    test_L_1hot = np.array([[loader.label_to_onehot(digit)] for digit in test_L.T])\n",
    "    test_L_1hot = np.transpose(test_L_1hot, (1,2,0,3))\n",
    "    test_L_1hot = test_L_1hot.reshape((-1, 7 * 10))\n",
    "\n",
    "    trainer.train_dataset.append(train_L_1hot)\n",
    "    trainer.test_dataset.append(test_L_1hot)\n",
    "\n",
    "    _log('data validation...', end='\\r\\n')\n",
    "\n",
    "    # To check image input\n",
    "    _log('input image data shape : ', end='')\n",
    "    _log(trainer.train_dataset[0].shape)\n",
    "\n",
    "    # To check label input\n",
    "    _log('input label data shape : ', end='')\n",
    "    _log(trainer.train_dataset[1].shape)\n",
    "\n",
    "    _log('training...')\n",
    "    trainer.set_model()\n",
    "    trainer.train(for_training=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy 00.71\n",
      "....................\n",
      "epoch  180 -> loss : 01.36 / training_accuracy: 00.85\n",
      "....................\n",
      "epoch  160 -> loss : 01.99 / training_accuracy: 00.79\n",
      "....................\n",
      "epoch  140 -> loss : 04.07 / training_accuracy: 00.72\n",
      "....................\n",
      "epoch  120 -> loss : 05.69 / training_accuracy: 00.65\n",
      "....................\n",
      "epoch  100 -> loss : 06.33 / training_accuracy: 00.65\n",
      "....................\n",
      "epoch   80 -> loss : 07.33 / training_accuracy: 00.61\n",
      "....................\n",
      "epoch   60 -> loss : 09.45 / training_accuracy: 00.53\n",
      "....................\n",
      "epoch   40 -> loss : 10.40 / training_accuracy: 00.48\n",
      "....................\n",
      "epoch   20 -> loss : 11.44 / training_accuracy: 00.45\n",
      "....................\n",
      "epoch    0 -> loss : 39.60 / training_accuracy: 00.41\n",
      "we're about to training using 5000 trainset...\n",
      "trainset size : 5000\n",
      "batch    size :   50\n",
      ". : 1 training epoch\n",
      "data validation...\n",
      "input image data shape : (5000, 64, 64)\n",
      "input label data shape : (5000,)\n",
      "training...\n",
      "input shape must be [None, 64, 64]\n",
      "data loading...\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # train_for_mnist_normal()\n",
    "    train_for_mnist_synthetic()\n",
    "    # train_for_svhn_synthetic()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "\n",
    "### Question 1\n",
    "_What approach did you take in coming up with a solution to this problem?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Answer:**\n",
    "\n",
    " The most difficult part of solving this problem was the process of creating a dataset by attaching MNIST images successively.\n",
    "\n",
    "The first approach to machine learning was as follows. I had to first decide what to do with the label. So, I labeled a total of seven pieces of information, including length information for numbers, five digits for each digit, and one space for the last unimportant digit.\n",
    "\n",
    "After that I saw the video mentioned on the Udacity notebook before creating a machine learning model. It was a video related to the SVHN problem, mentioning that the problem was a total of eleven layers, and was a video explaining how to label each piece of information.\n",
    "\n",
    "When I look at the video, I decided to make the model deeper by assuming it was difficult to predict the problem with LeNet (Convolution layer 2, Fully connected layer 2) given by Tensorflow's CovNet example. So I went to Convolution 5, Fully connected 2.\n",
    "\n",
    "At first, I designed and trained parameters and labels based on the Tensorflow example, but there was a problem that I did not get as accurate as I thought. So I decided to change the approach somewhat.\n",
    "\n",
    "In the example, there was one type of label information (10 one-hot encodings), but in this case a total of seven pieces of information had to be described, so applying one-hot encoding at one time resulted in too many labels.\n",
    "\n",
    "At first I did not think this would affect performance, and I thought about how to improve it because it was hard to debug and improve the model.\n",
    "\n",
    "  To improve on this, I decided to take the softmax of each element (length, 5 digits, blank) and consider the LOSS of this model as the sum of these. And we applied L2 regulator to this loss function so that we can find the optimal point more quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Question 2\n",
    "_What does your final architecture look like? (Type of model, layers, sizes, connectivity, etc.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Answer:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Finally, the model I created was the Convolution Neural Network.\n",
    "\n",
    "The layer uses four Convolution Layers and two Fully Connected Layers.\n",
    "\n",
    "At each Convolution Layer we did 2x2 Max Pooling and used ReLU as our Activation Function. In the Fully Connected Layer, I tried to Regularize the information by applying Dropout, respectively.\n",
    "\n",
    "Here, the Loss function is constructed by using a total of 7 softmaxs, one for the number of digits, the number of digits, and a blank space, and tried to reach the optimum value more quickly by configuring the L2 Regularizer.\n",
    "\n",
    "As an optimizer, we have chosen AdamOptimer to reach the optimal value faster than the existing gradient descent. (AdamOptimier adds an acceleration concept to the GradientDescentOptimier, which means that the vibration is reduced to reach the optimum value more quickly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Question 3\n",
    "_How did you train your model? How did you generate your synthetic dataset?_ Include examples of images from the synthetic data you constructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Using the numerical images provided by MNIST, images were generated according to the random number generated. (See below for results)\n",
    "\n",
    "At this time, 1000 images were created for each digit length in order to study various digit numbers. Even if the same number appears, the images will not be the same because you made the images randomly selected.\n",
    "\n",
    "For example, if you create a 1000 number of 1 length digits, the image will be as many as the number of images provided by MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7gAAABcCAYAAABEBBlSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0AWuUkoppZRSSqkT4f8AsUEnGqt/DGoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7cffb34650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7gAAABcCAYAAABEBBlSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d0096b9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified train_32x32.mat\n",
      "Found and verified test_32x32.mat\n",
      "Found and verified extra_32x32.mat\n",
      "Found and verified train-images-idx3-ubyte.gz\n",
      "Found and verified train-labels-idx1-ubyte.gz\n",
      "Found and verified t10k-images-idx3-ubyte.gz\n",
      "Found and verified t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    mnist_loader = MNISTLoader()\n",
    "    svhn_loader = SVHNLoader()\n",
    "\n",
    "    mnist_loader.download_data()\n",
    "    svhn_loader.download_data()\n",
    "\n",
    "    mnist_loader.init_data()\n",
    "    svhn_loader.init_data()\n",
    "\n",
    "    mnist_mixed_set = mnist_loader.get_mixed_data()\n",
    "    svhn_mixed_set = svhn_loader.get_mixed_data()\n",
    "\n",
    "    mnist_loader.validate_data(mnist_mixed_set[0],\n",
    "                               mnist_mixed_set[1], 64, 64)\n",
    "    svhn_loader.validate_data(svhn_mixed_set[0],\n",
    "                              svhn_mixed_set[1], 64, 64)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### data_loader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import gzip\n",
    "import os\n",
    "import os.path\n",
    "import struct\n",
    "import tarfile\n",
    "from array import array as pyarray\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.misc import imresize\n",
    "\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "\n",
    "_DEBUG = True\n",
    "\n",
    "\n",
    "def _log(message):\n",
    "    if _DEBUG:\n",
    "        print(message)\n",
    "\n",
    "\n",
    "class Loader(object):\n",
    "\n",
    "    pickle_prefix = None\n",
    "    base_url = None\n",
    "    dest_folder = None\n",
    "\n",
    "    image_width = None\n",
    "    image_height = None\n",
    "    image_channel = None\n",
    "\n",
    "    training_data_digits = None\n",
    "    testing_data_digits = None\n",
    "\n",
    "    training_data = None\n",
    "    testing_data = None\n",
    "\n",
    "    training_mixed_data = None\n",
    "    testing_mixed_data = None\n",
    "\n",
    "    @staticmethod\n",
    "    def maybe_download(base_url, dest_folder, filename, expected_bytes=None):\n",
    "        if not os.path.exists(dest_folder):\n",
    "            os.makedirs(dest_folder)\n",
    "\n",
    "        filepath = os.path.join(dest_folder, filename)\n",
    "\n",
    "        if not os.path.exists(filepath):\n",
    "            filepath, _ = urlretrieve(base_url + filename, filepath)\n",
    "\n",
    "        statinfo = os.stat(filepath)\n",
    "\n",
    "        if expected_bytes is None or statinfo.st_size == expected_bytes:\n",
    "            print('Found and verified %s' % filename)\n",
    "        else:\n",
    "            print(statinfo.st_size)\n",
    "            raise Exception('Failed to verify ' + filename +\n",
    "                            '. Can you get to it with a browser ?')\n",
    "        return filename\n",
    "\n",
    "    @staticmethod\n",
    "    def maybe_untargz(filename, dest_folder, force=False):\n",
    "        extraction_dir = filename.split('.')[0]\n",
    "        if not os.path.isdir(extraction_dir):\n",
    "            tar = tarfile.open(filename, 'r:gz')\n",
    "            tar.extractall(dest_folder)\n",
    "            tar.close()\n",
    "\n",
    "            print(filename + \" extracted to \" + extraction_dir)\n",
    "        else:\n",
    "            print(\"Folder\" + extraction_dir + \" already exists. Skipping\")\n",
    "\n",
    "    @staticmethod\n",
    "    def saveAsPickle(images, filename):\n",
    "        try:\n",
    "            with open(filename, 'wb') as f:\n",
    "                pickle.dump(images, f, pickle.HIGHEST_PROTOCOL)\n",
    "                print(filename + \" pickled!\")\n",
    "        except Exception as e:\n",
    "            print('Unable to save images to ', filename, ':', e)\n",
    "\n",
    "    @staticmethod\n",
    "    def loadPickle(file):\n",
    "        with open(file, 'rb') as pickle_file:\n",
    "            return pickle.load(pickle_file)\n",
    "\n",
    "    @staticmethod\n",
    "    def split_validation(train_data, train_label, split_ratio=0.9):\n",
    "\n",
    "        permutation_indices = np.random.permutation(train_data.shape[0])\n",
    "        split_pos = int(train_data.shape[0] * split_ratio)\n",
    "\n",
    "        train_data_reidx = train_data[permutation_indices]\n",
    "        valid_dt_set = train_data_reidx[split_pos:]\n",
    "        train_dt_set = train_data_reidx[:split_pos]\n",
    "\n",
    "        train_lb_reidx = train_label[permutation_indices]\n",
    "        valid_lb_set = train_lb_reidx[split_pos:]\n",
    "        train_lb_set = train_lb_reidx[:split_pos]\n",
    "\n",
    "        return (train_dt_set, train_lb_set, valid_dt_set, valid_lb_set)\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_numbers(max_number, size):\n",
    "        return np.random.randint(max_number, size=size)\n",
    "\n",
    "    @staticmethod\n",
    "    def label_to_onehot(original):\n",
    "        decimal_kind_of_digit = 10\n",
    "\n",
    "        count_distinct_value = max(len(np.unique(original)), decimal_kind_of_digit)\n",
    "        label_1hot = np.zeros((original.shape[0], count_distinct_value))\n",
    "        label_1hot[np.arange(original.shape[0]), np.transpose(original)] = 1\n",
    "\n",
    "        return label_1hot\n",
    "\n",
    "    @staticmethod\n",
    "    def onehot_to_label(encoded):\n",
    "        return np.array([np.where(e == 1)[0]\n",
    "                         for e in np.rollaxis(encoded,0)]).reshape([-1])\n",
    "\n",
    "\n",
    "    def init_data(self):\n",
    "        raise NotImplementedError('Should have implemented this')\n",
    "\n",
    "    def generate_mixed_digit_data(self,\n",
    "                                  numbers,\n",
    "                                  scale=1,\n",
    "                                  max_length=6,\n",
    "                                  dims=(64, 64)):\n",
    "        raise NotImplementedError('Should have implemented this')\n",
    "\n",
    "    def get_data(self, dataset=\"training\"):\n",
    "        if not self.training_data_digits or not self.testing_data_digits:\n",
    "            raise AssertionError('MNIST dataset may be initialized.')\n",
    "\n",
    "        if dataset == \"training\":\n",
    "            return self.training_data\n",
    "        else:\n",
    "            return self.testing_data\n",
    "\n",
    "    def get_digit_data(self, digit, dataset=\"training\"):\n",
    "        if not self.training_data_digits or not self.testing_data_digits:\n",
    "            raise AssertionError('MNIST dataset may be initialized.')\n",
    "\n",
    "        if dataset == \"training\":\n",
    "            return self.training_data_digits[digit]\n",
    "        else:\n",
    "            return self.testing_data_digits[digit]\n",
    "\n",
    "    def get_mixed_data(self, dataset=\"training\"):\n",
    "\n",
    "        if not os.path.exists(self.dest_folder):\n",
    "            os.makedirs(self.dest_folder)\n",
    "\n",
    "        if not os.path.exists(\n",
    "                os.path.join(self.dest_folder,\n",
    "                             self.pickle_prefix + \"_training_mixed_set.pickle\")):\n",
    "\n",
    "            trainset_lbl = list()\n",
    "            trainset_lbl += Loader.generate_numbers(9, 1000).tolist()\n",
    "            trainset_lbl += Loader.generate_numbers(99, 1000).tolist()\n",
    "            trainset_lbl += Loader.generate_numbers(999, 1000).tolist()\n",
    "            trainset_lbl += Loader.generate_numbers(9999, 1000).tolist()\n",
    "            trainset_lbl += Loader.generate_numbers(99999, 1000).tolist()\n",
    "\n",
    "            trainset_lbl = np.array(trainset_lbl)\n",
    "            trainset_lbl = trainset_lbl[np.random.permutation(trainset_lbl.shape[0])]\n",
    "            trainset_lbl.reshape(trainset_lbl.shape[0])\n",
    "\n",
    "            trainset_data = self.generate_mixed_digit_data(trainset_lbl)\n",
    "            self.training_mixed_data = trainset_data\n",
    "\n",
    "            Loader.saveAsPickle(self.training_mixed_data,\n",
    "                                os.path.join(self.dest_folder,\n",
    "                                             self.pickle_prefix + \"_training_mixed_set.pickle\"))\n",
    "\n",
    "        self.training_mixed_data = Loader.loadPickle(os.path.join(self.dest_folder,\n",
    "                                             self.pickle_prefix + \"_training_mixed_set.pickle\"))\n",
    "\n",
    "        if not os.path.exists(\n",
    "                os.path.join(self.dest_folder,\n",
    "                             self.pickle_prefix + \"_testing_mixed_set.pickle\")):\n",
    "\n",
    "            testset_lbl = list()\n",
    "            testset_lbl += Loader.generate_numbers(9, 400).tolist()\n",
    "            testset_lbl += Loader.generate_numbers(99, 400).tolist()\n",
    "            testset_lbl += Loader.generate_numbers(999, 400).tolist()\n",
    "            testset_lbl += Loader.generate_numbers(9999, 400).tolist()\n",
    "            testset_lbl += Loader.generate_numbers(99999, 400).tolist()\n",
    "\n",
    "            testset_lbl = np.array(testset_lbl)\n",
    "            testset_lbl = testset_lbl[np.random.permutation(testset_lbl.shape[0])]\n",
    "            testset_lbl.reshape(testset_lbl.shape[0])\n",
    "\n",
    "            testset_data = self.generate_mixed_digit_data(testset_lbl)\n",
    "            self.testing_mixed_data = testset_data\n",
    "\n",
    "            Loader.saveAsPickle(self.testing_mixed_data,\n",
    "                                os.path.join(self.dest_folder,\n",
    "                                             self.pickle_prefix + \"_testing_mixed_set.pickle\"))\n",
    "\n",
    "        self.testing_mixed_data = Loader.loadPickle(os.path.join(self.dest_folder,\n",
    "                                             self.pickle_prefix + \"_testing_mixed_set.pickle\"))\n",
    "\n",
    "        if dataset == \"training\":\n",
    "            return self.training_mixed_data\n",
    "        else:\n",
    "            return self.testing_mixed_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "[0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "class MNISTLoader(Loader):\n",
    "\n",
    "    training_data_digits = None\n",
    "    testing_data_digits = None\n",
    "\n",
    "    training_data = None\n",
    "    testing_data = None\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.pickle_prefix = 'mnist'\n",
    "        self.dest_folder = 'MNIST_data/'\n",
    "        self.base_url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "\n",
    "        self.image_width = 28\n",
    "        self.image_height = 28\n",
    "        self.image_channel = 1\n",
    "\n",
    "    def download_data(self):\n",
    "        mnist_train_images = Loader.maybe_download(\n",
    "            self.base_url, self.dest_folder, 'train-images-idx3-ubyte.gz',\n",
    "            9912422)\n",
    "        mnist_train_labels = Loader.maybe_download(\n",
    "            self.base_url, self.dest_folder, 'train-labels-idx1-ubyte.gz',\n",
    "            28881)\n",
    "        mnist_test_images = Loader.maybe_download(\n",
    "            self.base_url, self.dest_folder, 't10k-images-idx3-ubyte.gz',\n",
    "            1648877)\n",
    "        mnist_test_labels = Loader.maybe_download(\n",
    "            self.base_url, self.dest_folder, 't10k-labels-idx1-ubyte.gz', 4542)\n",
    "\n",
    "        files = [mnist_train_images, mnist_train_labels]\n",
    "\n",
    "        for file in files:\n",
    "            filepath = os.path.join(self.dest_folder, file)\n",
    "            inF = gzip.open(filepath, 'rb')\n",
    "            outF = open(filepath.split(\".\", 2)[0], 'wb')\n",
    "            outF.write(inF.read())\n",
    "            inF.close()\n",
    "            outF.close()\n",
    "\n",
    "    def init_data(self):\n",
    "        if self.training_data_digits or self.testing_data_digits:\n",
    "            raise AssertionError('MNIST dataset may be initialized.')\n",
    "\n",
    "        if not os.path.exists(\n",
    "                os.path.join(self.dest_folder, \"mnist_training_all.pickle\")):\n",
    "            self.training_data = self.__load_data(dataset=\"training\", path=self.dest_folder)\n",
    "            Loader.saveAsPickle(self.training_data,\n",
    "                                os.path.join(self.dest_folder,\n",
    "                                             \"mnist_training_all.pickle\"))\n",
    "\n",
    "        if not os.path.exists(\n",
    "                os.path.join(self.dest_folder, \"mnist_testing_all.pickle\")):\n",
    "            self.testing_data = self.__load_data(dataset=\"testing\", path=self.dest_folder)\n",
    "            Loader.saveAsPickle(self.testing_data,\n",
    "                                os.path.join(self.dest_folder,\n",
    "                                             \"mnist_testing_all.pickle\"))\n",
    "\n",
    "        for i in range(10):\n",
    "            l = list()\n",
    "            l.append(i)\n",
    "\n",
    "            if not os.path.exists(\n",
    "                    os.path.join(self.dest_folder, \"mnist_training_digit_\" +\n",
    "                                 str(i) + \".pickle\")):\n",
    "                d = self.__load_data(\n",
    "                    dataset=\"training\",\n",
    "                    digits=l,\n",
    "                    path=self.dest_folder,\n",
    "                    asbytes=False,\n",
    "                    selection=None,\n",
    "                    return_labels=True,\n",
    "                    return_indices=False)\n",
    "\n",
    "                Loader.saveAsPickle(\n",
    "                    d,\n",
    "                    os.path.join(self.dest_folder,\n",
    "                                 \"mnist_training_digit_\" + str(i) + \".pickle\"))\n",
    "\n",
    "            if not os.path.exists(\n",
    "                    os.path.join(self.dest_folder, \"mnist_testing_digit_\" +\n",
    "                                 str(i) + \".pickle\")):\n",
    "\n",
    "                d = self.__load_data(\n",
    "                    dataset=\"testing\",\n",
    "                    digits=l,\n",
    "                    path=self.dest_folder,\n",
    "                    asbytes=False,\n",
    "                    selection=None,\n",
    "                    return_labels=True,\n",
    "                    return_indices=False)\n",
    "\n",
    "                Loader.saveAsPickle(\n",
    "                    d,\n",
    "                    os.path.join(self.dest_folder,\n",
    "                                 \"mnist_testing_digit_\" + str(i) + \".pickle\"))\n",
    "\n",
    "        self.training_data = Loader.loadPickle(\n",
    "                os.path.join(self.dest_folder,\n",
    "                             \"mnist_training_all.pickle\"))\n",
    "\n",
    "        self.testing_data = Loader.loadPickle(\n",
    "            os.path.join(self.dest_folder,\n",
    "                         \"mnist_testing_all.pickle\"))\n",
    "\n",
    "        self.training_data_digits = [\n",
    "            Loader.loadPickle(\n",
    "                os.path.join(self.dest_folder, \"mnist_training_digit_\" + str(i)\n",
    "                             + \".pickle\")) for i in range(10)\n",
    "        ]\n",
    "\n",
    "        self.testing_data_digits = [\n",
    "            Loader.loadPickle(\n",
    "                os.path.join(self.dest_folder, \"mnist_testing_digit_\" + str(i)\n",
    "                             + \".pickle\")) for i in range(10)\n",
    "        ]\n",
    "\n",
    "\n",
    "    def __load_data(self,\n",
    "                    dataset=\"training\",\n",
    "                    digits=None,\n",
    "                    path=\"\",\n",
    "                    asbytes=False,\n",
    "                    selection=None,\n",
    "                    return_labels=True,\n",
    "                    return_indices=False):\n",
    "        \"\"\"\n",
    "        from: https://raw.githubusercontent.com/amitgroup/amitgroup/master/amitgroup/io/mnist.py\n",
    "        Loads MNIST files into a 3D numpy array.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset : str\n",
    "            Either \"training\" or \"testing\", depending on which dataset you want to\n",
    "            load.\n",
    "        digits : list\n",
    "            Integer list of digits to load. The entire database is loaded if set to\n",
    "            ``None``. Default is ``None``.\n",
    "        path : str\n",
    "            Path to your MNIST datafiles. The default is ``None``, which will try\n",
    "            to take the path from your environment variable ``MNIST``. The images can\n",
    "            be downloaded from http://yann.lecun.com/exdb/mnist/.\n",
    "        asbytes : bool\n",
    "            If True, returns images as ``numpy.uint8`` in [0, 255] as opposed to\n",
    "            ``numpy.float64`` in [0.0, 1.0].\n",
    "        selection : slice\n",
    "            Using a `slice` object, specify what subset of the dataset to load. An\n",
    "            example is ``slice(0, 20, 2)``, which would load every other digit\n",
    "            until--but not including--the twentieth.\n",
    "        return_labels : bool\n",
    "            Specify whether or not labels should be returned. This is also a speed\n",
    "            performance if digits are not specified, since then the labels file\n",
    "            does not need to be read at all.\n",
    "        return_indicies : bool\n",
    "            Specify whether or not to return the MNIST indices that were fetched.\n",
    "            This is valuable only if digits is specified, because in that case it\n",
    "            can be valuable to know how far\n",
    "            in the database it reached.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        images : ndarray\n",
    "            Image images of shape ``(N, rows, cols)``, where ``N`` is the numbers of images. If neither labels nor inices are returned, then this is returned directly, and not inside a 1-sized tuple.\n",
    "        labels : ndarray\n",
    "            Array of size ``N`` describing the labels. Returned only if ``return_labels`` is `True`, which is default.\n",
    "        indices : ndarray\n",
    "            The indices in the database that were returned.\n",
    "        \"\"\"\n",
    "\n",
    "        # The files are assumed to have these names and should be found in\n",
    "        # 'path'\n",
    "        files = {\n",
    "            'training': ('train-images-idx3-ubyte', 'train-labels-idx1-ubyte'),\n",
    "            'testing': ('t10k-images-idx3-ubyte', 't10k-labels-idx1-ubyte'),\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            images_fname = os.path.join(path, files[dataset][0])\n",
    "            labels_fname = os.path.join(path, files[dataset][1])\n",
    "        except KeyError:\n",
    "            raise ValueError(\"Data set must be 'testing' or 'training'\")\n",
    "\n",
    "        # We can skip the labels file only if digits aren't specified and\n",
    "        # labels aren't asked for\n",
    "        if return_labels or digits is not None:\n",
    "            flbl = open(labels_fname, 'rb')\n",
    "            magic_nr, size = struct.unpack(\">II\", flbl.read(8))\n",
    "            labels_raw = pyarray(\"b\", flbl.read())\n",
    "            flbl.close()\n",
    "\n",
    "        fimg = open(images_fname, 'rb')\n",
    "        magic_nr, size, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        images_raw = pyarray(\"B\", fimg.read())\n",
    "        fimg.close()\n",
    "\n",
    "        if digits:\n",
    "            indices = [k for k in range(size) if labels_raw[k] in digits]\n",
    "        else:\n",
    "            indices = range(size)\n",
    "\n",
    "        if selection:\n",
    "            indices = indices[selection]\n",
    "        N = len(indices)\n",
    "\n",
    "        images = np.zeros((N, rows, cols), dtype=np.uint8)\n",
    "\n",
    "        if return_labels:\n",
    "            labels = np.zeros((N), dtype=np.int8)\n",
    "        for i, index in enumerate(indices):\n",
    "            images[i] = np.array(images_raw[indices[i] * rows * cols:(indices[\n",
    "                i] + 1) * rows * cols]).reshape((rows, cols))\n",
    "            if return_labels:\n",
    "                labels[i] = labels_raw[indices[i]]\n",
    "\n",
    "        if not asbytes:\n",
    "            images = images.astype(float) / 255.\n",
    "\n",
    "        ret = (images, )\n",
    "        if return_labels:\n",
    "            ret += (labels, )\n",
    "        if return_indices:\n",
    "            ret += (indices, )\n",
    "        if len(ret) == 1:\n",
    "            return ret[0]  # Don't return a tuple of one\n",
    "        else:\n",
    "            return ret\n",
    "\n",
    "    def validate_data(self, images, labels, height=None, width=None):\n",
    "        \"\"\"\n",
    "        Prints digits as image along with their labels\n",
    "        \"\"\"\n",
    "\n",
    "        valid_size = min(images.shape[0], 12)\n",
    "        height = self.image_height if not height else height\n",
    "        width = self.image_width if not width else width\n",
    "\n",
    "        if _DEBUG:\n",
    "            img_data = (images * 255).astype(int)\n",
    "            img_labels = labels\n",
    "\n",
    "            indices = np.random.randint(\n",
    "                img_data.shape[0] - 1,\n",
    "                size=valid_size) if valid_size > 12 else range(valid_size)\n",
    "            fig = plt.figure(figsize=(12, 3), dpi=80)\n",
    "\n",
    "            for i, idx in enumerate(indices):\n",
    "                plt.subplot(1, valid_size, i + 1)\n",
    "                plt.title(img_labels[idx])\n",
    "                plt.imshow(\n",
    "                    img_data[idx].reshape(height, width),\n",
    "                    interpolation='nearest',\n",
    "                    cmap='Greys')\n",
    "                plt.tight_layout()\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "    def __get_digit_data_rand(self, digit, dataset=\"training\"):\n",
    "        if not self.training_data_digits or not self.testing_data_digits:\n",
    "            raise AssertionError('MNIST dataset may be initialized.')\n",
    "\n",
    "        if dataset == \"training\":\n",
    "            return self.training_data_digits[digit][0][np.random.randint(\n",
    "                self.training_data_digits[digit][0].shape[0])].reshape(\n",
    "                    self.image_height, self.image_width)\n",
    "        else:\n",
    "            return self.testing_data_digits[digit][0][np.random.randint(\n",
    "                self.testing_data_digits[digit][0].shape[0])].reshape(\n",
    "                    self.image_height, self.image_width)\n",
    "\n",
    "    def generate_mixed_digit_data(self,\n",
    "                                  numbers,\n",
    "                                  scale=1,\n",
    "                                  max_length=6,\n",
    "                                  dims=(64, 64)):\n",
    "\n",
    "        images = np.zeros([len(numbers), dims[0], dims[1]])\n",
    "        values = np.zeros(len(numbers)).astype(int)\n",
    "        lengths = np.zeros([\n",
    "            len(numbers),\n",
    "        ]).astype(int)\n",
    "        digits = np.zeros([len(numbers), 6]).astype(int)\n",
    "\n",
    "        for i, number in enumerate(numbers):\n",
    "            _log('generate %d\\'s image...' % number)\n",
    "            values[i] = int(number)\n",
    "\n",
    "            # To store numbers list into digits list\n",
    "            # if number is [123, 456], it will store [[1,2,3], [4,5,6]]\n",
    "            num_digits = [int(j) for j in list(str(values[i]))]\n",
    "            lengths[i] = min(len(num_digits), 6)\n",
    "            digits[i, 0:lengths[i]] = num_digits[:lengths[i]]\n",
    "\n",
    "            lengths[i] -= 1\n",
    "\n",
    "            # generate mixed images. it will just paste images to righthand direction\n",
    "            num_images = np.zeros(\n",
    "                [self.image_height, self.image_width * len(num_digits)])\n",
    "            for j, digit in enumerate(num_digits):\n",
    "\n",
    "                v = self.__get_digit_data_rand(digit)\n",
    "                num_images[0:self.image_height, j * self.image_width:(j + 1) *\n",
    "                           self.image_width] = self.__get_digit_data_rand(\n",
    "                               digit)\n",
    "\n",
    "            # make pasted images to 64x64 matrix\n",
    "            scale = float(dims[0]) / (self.image_width * (lengths[i] + 1))\n",
    "            if scale != 1:\n",
    "                num_images = imresize(num_images, scale, interp='bilinear')\n",
    "\n",
    "            # make image list\n",
    "            max_top = dims[0] - num_images.shape[0]\n",
    "            max_left = dims[1] - num_images.shape[1]\n",
    "\n",
    "            top = np.random.randint(0, max_top) if max_top > 0 else 0\n",
    "            left = np.random.randint(0, max_left) if max_left > 0 else 0\n",
    "\n",
    "            images[i, top:top + num_images.shape[0], left:left +\n",
    "                   num_images.shape[1]] = num_images\n",
    "\n",
    "        return (images, values, digits, lengths)\n",
    "\n",
    "\n",
    "def testcase_for_loader():\n",
    "    mnist_loader = MNISTLoader()\n",
    "    svhn_loader = SVHNLoader()\n",
    "\n",
    "    mnist_loader.download_data()\n",
    "    svhn_loader.download_data()\n",
    "\n",
    "    mnist_loader.init_data()\n",
    "    svhn_loader.init_data()\n",
    "\n",
    "    dl1 = mnist_loader.get_digit_data(0, \"training\")\n",
    "    # mnist_loader.validate_data(dl1[0], dl1[1])\n",
    "\n",
    "    dt1 = mnist_loader.get_digit_data(0, \"testing\")\n",
    "    # mnist_loader.validate_data(dt1[0], dt1[1])\n",
    "\n",
    "    dl2 = svhn_loader.get_digit_data(1, \"training\")\n",
    "    # svhn_loader.validate_data(dl2[0], dl2[1])\n",
    "\n",
    "    dt2 = svhn_loader.get_digit_data(1, \"testing\")\n",
    "    # svhn_loader.validate_data(dt2[0], dt2[1])\n",
    "\n",
    "    mnist_mixed_set = mnist_loader.get_mixed_data()\n",
    "    svhn_mixed_set = svhn_loader.get_mixed_data()\n",
    "\n",
    "    mnist_loader.validate_data(mnist_mixed_set[0],\n",
    "                               mnist_mixed_set[1], 64, 64)\n",
    "    svhn_loader.validate_data(svhn_mixed_set[0],\n",
    "                              svhn_mixed_set[1], 64, 64)\n",
    "\n",
    "    # cross validation testcase\n",
    "    for i in range(0, 10):\n",
    "        da = Loader.loadPickle(\n",
    "            os.path.join(mnist_loader.dest_folder, \"mnist_training_digit_\" +\n",
    "                         str(i) + \".pickle\"))\n",
    "        # mnist_loader.validate_data(da)\n",
    "\n",
    "        train_dt, train_lb, valid_dt, valid_lb = Loader.split_validation(\n",
    "            dl1[0], dl1[1])\n",
    "\n",
    "        print('train_dt size : %d' % train_dt.shape[0])\n",
    "        print('train_lb size : %d' % train_lb.shape[0])\n",
    "        print('valid_dt size : %d' % valid_dt.shape[0])\n",
    "        print('valid_lb size : %d' % valid_lb.shape[0])\n",
    "\n",
    "\n",
    "def main():\n",
    "    # testcase_for_loader()\n",
    "\n",
    "    encoded = Loader.label_to_onehot(\n",
    "            np.array([0, 1, 2, 3, 4, 5]).reshape(6, 1))\n",
    "\n",
    "    print(encoded)\n",
    "\n",
    "    decoded = Loader.onehot_to_label(encoded)\n",
    "\n",
    "    print(decoded)\n",
    "\n",
    "    # # mnist images serialization testcase\n",
    "    # training_data_digits = list()\n",
    "    # for i in range(10):\n",
    "    #     l = list()\n",
    "    #     l.append(i)\n",
    "\n",
    "    #     d = mnist_loader.__load_data(\n",
    "    #         dataset=\"training\",\n",
    "    #         digits=l,\n",
    "    #         path=mnist_loader.dest_folder,\n",
    "    #         asbytes=False,\n",
    "    #         selection=None,\n",
    "    #         return_labels=True,\n",
    "    #         return_indices=False)\n",
    "\n",
    "    #     Loader.saveAsPickle(\n",
    "    #         d,\n",
    "    #         os.path.join(mnist_loader.dest_folder,\n",
    "    #                      \"mnist_training_digit_\" + str(i) + \".pickle\"))\n",
    "    #     training_data_digits.append(d)\n",
    "\n",
    "    # # serialize svhn images into pickle format\n",
    "    # for i in range(10):\n",
    "\n",
    "    #     d = svhn_loader.__load_data('training', digits=i)\n",
    "\n",
    "    #     Loader.saveAsPickle(\n",
    "    #         d,\n",
    "    #         os.path.join(svhn_loader.dest_folder,\n",
    "    #                      \"svhn_training_digit_\" + str(i) + \".pickle\"))\n",
    "\n",
    "    # for i in range(0, 10):\n",
    "\n",
    "    #     da = Loader.loadPickle(\n",
    "    #         os.path.join(svhn_loader.dest_folder, \"svhn_training_digit_\" + str(\n",
    "    #             i) + \".pickle\"))\n",
    "    #     # svhn_loader.validate_data(da)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class SVHNLoader(Loader):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.pickle_prefix = 'svhn'\n",
    "        self.dest_folder = 'SVHN_data/'\n",
    "        self.base_url = 'http://ufldl.stanford.edu/housenumbers/'\n",
    "\n",
    "        self.image_width = 32\n",
    "        self.image_height = 32\n",
    "        self.image_channel = 3\n",
    "\n",
    "    def init_data(self):\n",
    "        if self.training_data_digits or self.testing_data_digits:\n",
    "            raise AssertionError('svhn dataset may be initialized.')\n",
    "\n",
    "        if not os.path.exists(\n",
    "                os.path.join(self.dest_folder, \"svhn_training_all.pickle\")):\n",
    "            self.training_data = self.__load_data(dataset=\"training\")\n",
    "            Loader.saveAsPickle(self.training_data,\n",
    "                                os.path.join(self.dest_folder,\n",
    "                                             \"svhn_training_all.pickle\"))\n",
    "\n",
    "        if not os.path.exists(\n",
    "                os.path.join(self.dest_folder, \"svhn_testing_all.pickle\")):\n",
    "            self.testing_data = self.__load_data(dataset=\"testing\")\n",
    "            Loader.saveAsPickle(self.testing_data,\n",
    "                                os.path.join(self.dest_folder,\n",
    "                                             \"svhn_testing_all.pickle\"))\n",
    "\n",
    "        for i in range(10):\n",
    "            l = list()\n",
    "            l.append(i)\n",
    "\n",
    "            if not os.path.exists(\n",
    "                    os.path.join(self.dest_folder, \"svhn_training_digit_\" +\n",
    "                                 str(i) + \".pickle\")):\n",
    "                d = self.__load_data(dataset=\"training\", digits=l)\n",
    "\n",
    "                Loader.saveAsPickle(\n",
    "                    d,\n",
    "                    os.path.join(self.dest_folder,\n",
    "                                 \"svhn_training_digit_\" + str(i) + \".pickle\"))\n",
    "\n",
    "            if not os.path.exists(\n",
    "                    os.path.join(self.dest_folder, \"svhn_testing_digit_\" + str(\n",
    "                        i) + \".pickle\")):\n",
    "\n",
    "                d = self.__load_data(dataset=\"testing\", digits=i)\n",
    "\n",
    "                Loader.saveAsPickle(\n",
    "                    d,\n",
    "                    os.path.join(self.dest_folder,\n",
    "                                 \"svhn_testing_digit_\" + str(i) + \".pickle\"))\n",
    "\n",
    "        self.training_data = Loader.loadPickle(\n",
    "                os.path.join(self.dest_folder,\n",
    "                             \"svhn_training_all.pickle\"))\n",
    "\n",
    "        self.testing_data = Loader.loadPickle(\n",
    "            os.path.join(self.dest_folder,\n",
    "                         \"svhn_testing_all.pickle\"))\n",
    "\n",
    "        self.training_data_digits = [\n",
    "            Loader.loadPickle(\n",
    "                os.path.join(self.dest_folder, \"svhn_training_digit_\" + str(i)\n",
    "                             + \".pickle\")) for i in range(10)\n",
    "        ]\n",
    "\n",
    "        self.testing_data_digits = [\n",
    "            Loader.loadPickle(\n",
    "                os.path.join(self.dest_folder, \"svhn_testing_digit_\" + str(i) +\n",
    "                             \".pickle\")) for i in range(10)\n",
    "        ]\n",
    "\n",
    "    def download_data(self):\n",
    "        svhn_train_images = Loader.maybe_download(\n",
    "            self.base_url, self.dest_folder, 'train_32x32.mat', 182040794)\n",
    "        svhn_test_images = Loader.maybe_download(\n",
    "            self.base_url, self.dest_folder, 'test_32x32.mat', 64275384)\n",
    "        svhn_extra_images = Loader.maybe_download(\n",
    "            self.base_url, self.dest_folder, 'extra_32x32.mat', 1329278602)\n",
    "\n",
    "    def __load_data(self, dataset='training', digits=None):\n",
    "        files = {'training': 'train_32x32.mat', 'testing': 'test_32x32.mat'}\n",
    "\n",
    "        try:\n",
    "            data_fname = os.path.join(self.dest_folder, files[dataset])\n",
    "        except KeyError:\n",
    "            raise ValueError(\"Data set must be 'testing' or 'training'\")\n",
    "\n",
    "        loaded_dict = sio.loadmat(data_fname)\n",
    "        X = loaded_dict['X']\n",
    "\n",
    "        # change the matrix's shape\n",
    "        X_ret = []\n",
    "        for i in range(X.shape[3]):\n",
    "            X_ret.append(X[:, :, :, i])\n",
    "        X_ret = (np.asarray(X_ret).astype(float)) / 255.\n",
    " \n",
    "        # because the value of 10 has been represented '10',\n",
    "        # we would make it translated into '0'\n",
    "        y_ret = loaded_dict['y']\n",
    "\n",
    "        for i in range(len(y_ret)):\n",
    "            if not y_ret[i] % 10:\n",
    "                y_ret[i] = 0\n",
    "\n",
    "        # I'll use numpy advanced indexing for one-hot encoding implementation\n",
    "        y_ret_1hot = self.label_to_onehot(y_ret)\n",
    "\n",
    "        indices = []\n",
    "        if digits is not None:\n",
    "            indices = np.where(\n",
    "                y_ret == digits)[0]  # y_ret matrix was n by 1 matrix\n",
    "        else:\n",
    "            indices = range(y_ret.shape[0])\n",
    "\n",
    "        _log(\"%d of digit %s was selected : \" % (len(indices), digits))\n",
    "\n",
    "        ret = (X_ret[indices, :, :, :], )\n",
    "        ret += (y_ret[indices], )\n",
    "        ret += (y_ret_1hot[indices, :], )\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def validate_data(self, images, labels, height=None, width=None):\n",
    "        \"\"\"\n",
    "        Prints digits as image along with their labels\n",
    "        \"\"\"\n",
    "\n",
    "        valid_size = min(images.shape[0], 12)\n",
    "        height = self.image_height if not height else height\n",
    "        width = self.image_width if not width else width\n",
    "\n",
    "        if _DEBUG:\n",
    "            img_data = images\n",
    "            img_labels = labels\n",
    "\n",
    "            indices = np.random.randint(img_data.shape[0] - 1, size=valid_size)\n",
    "            fig = plt.figure(figsize=(12, 3), dpi=80)\n",
    "\n",
    "            for i, idx in enumerate(indices):\n",
    "                plt.subplot(1, valid_size, i + 1)\n",
    "                plt.title(img_labels[idx])\n",
    "                plt.imshow(img_data[idx], interpolation='nearest')\n",
    "                plt.tight_layout()\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "    def __get_digit_data_rand(self, digit, dataset=\"training\"):\n",
    "        if not self.training_data_digits or not self.testing_data_digits:\n",
    "            raise AssertionError('SVHN dataset may be initialized.')\n",
    "\n",
    "        if dataset == \"training\":\n",
    "            return self.training_data_digits[digit][0][np.random.randint(\n",
    "                self.training_data_digits[digit][0].shape[0])]\n",
    "        else:\n",
    "            return self.testing_data_digits[digit][0][np.random.randint(\n",
    "                self.testing_data_digits[digit][0].shape[0])]\n",
    "\n",
    "    def generate_mixed_digit_data(self,\n",
    "                                  numbers,\n",
    "                                  scale=1,\n",
    "                                  max_length=6,\n",
    "                                  dims=(64, 64)):\n",
    "\n",
    "        images = np.ones([len(numbers), dims[0], dims[1], self.image_channel])\n",
    "        values = np.zeros(len(numbers)).astype(int)\n",
    "        lengths = np.zeros([\n",
    "            len(numbers),\n",
    "        ]).astype(int)\n",
    "        digits = np.zeros([len(numbers), 6]).astype(int)\n",
    "\n",
    "        for i, number in enumerate(numbers):\n",
    "            values[i] = int(number)\n",
    "\n",
    "            # To store numbers list into digits list\n",
    "            # if number is [123, 456], it will store [[1,2,3], [4,5,6]]\n",
    "            num_digits = [int(j) for j in list(str(values[i]))]\n",
    "            lengths[i] = min(len(num_digits), 6)\n",
    "            digits[i, 0:lengths[i]] = num_digits[:lengths[i]]\n",
    "\n",
    "            # generate mixed images. it will just paste images to righthand direction\n",
    "            num_images = np.zeros([\n",
    "                self.image_height, self.image_width * len(num_digits),\n",
    "                self.image_channel\n",
    "            ])\n",
    "            for j, digit in enumerate(num_digits):\n",
    "\n",
    "                v = self.__get_digit_data_rand(digit)\n",
    "                num_images[0:self.image_height, j * self.image_width:(\n",
    "                    j + 1) * self.image_width, 0:self.\n",
    "                           image_channel] = self.__get_digit_data_rand(digit)\n",
    "\n",
    "            # make pasted images to 64x64 matrix\n",
    "            scale = float(dims[0]) / (self.image_width * (lengths[i] + 1))\n",
    "            if scale != 1:\n",
    "                num_images = imresize(num_images, scale, interp='bilinear')\n",
    "\n",
    "            # make image list\n",
    "            max_top = dims[0] - num_images.shape[0]\n",
    "            max_left = dims[1] - num_images.shape[1]\n",
    "\n",
    "            top = np.random.randint(0, max_top) if max_top > 0 else 0\n",
    "            left = np.random.randint(0, max_left) if max_left > 0 else 0\n",
    "\n",
    "            images[i, top:top + num_images.shape[0], left:left +\n",
    "                   num_images.shape[1], 0:self.image_channel] = num_images\n",
    "\n",
    "        return (images, values, digits, lengths)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "[0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "def testcase_for_loader():\n",
    "    mnist_loader = MNISTLoader()\n",
    "    svhn_loader = SVHNLoader()\n",
    "\n",
    "    mnist_loader.download_data()\n",
    "    svhn_loader.download_data()\n",
    "\n",
    "    mnist_loader.init_data()\n",
    "    svhn_loader.init_data()\n",
    "\n",
    "    dl1 = mnist_loader.get_digit_data(0, \"training\")\n",
    "    # mnist_loader.validate_data(dl1[0], dl1[1])\n",
    "\n",
    "    dt1 = mnist_loader.get_digit_data(0, \"testing\")\n",
    "    # mnist_loader.validate_data(dt1[0], dt1[1])\n",
    "\n",
    "    dl2 = svhn_loader.get_digit_data(1, \"training\")\n",
    "    # svhn_loader.validate_data(dl2[0], dl2[1])\n",
    "\n",
    "    dt2 = svhn_loader.get_digit_data(1, \"testing\")\n",
    "    # svhn_loader.validate_data(dt2[0], dt2[1])\n",
    "\n",
    "    mnist_mixed_set = mnist_loader.get_mixed_data()\n",
    "    svhn_mixed_set = svhn_loader.get_mixed_data()\n",
    "\n",
    "    mnist_loader.validate_data(mnist_mixed_set[0],\n",
    "                               mnist_mixed_set[1], 64, 64)\n",
    "    svhn_loader.validate_data(svhn_mixed_set[0],\n",
    "                              svhn_mixed_set[1], 64, 64)\n",
    "\n",
    "    # cross validation testcase\n",
    "    for i in range(0, 10):\n",
    "        da = Loader.loadPickle(\n",
    "            os.path.join(mnist_loader.dest_folder, \"mnist_training_digit_\" +\n",
    "                         str(i) + \".pickle\"))\n",
    "        # mnist_loader.validate_data(da)\n",
    "\n",
    "        train_dt, train_lb, valid_dt, valid_lb = Loader.split_validation(\n",
    "            dl1[0], dl1[1])\n",
    "\n",
    "        print('train_dt size : %d' % train_dt.shape[0])\n",
    "        print('train_lb size : %d' % train_lb.shape[0])\n",
    "        print('valid_dt size : %d' % valid_dt.shape[0])\n",
    "        print('valid_lb size : %d' % valid_lb.shape[0])\n",
    "\n",
    "\n",
    "def main():\n",
    "    # testcase_for_loader()\n",
    "\n",
    "    encoded = Loader.label_to_onehot(\n",
    "            np.array([0, 1, 2, 3, 4, 5]).reshape(6, 1))\n",
    "\n",
    "    print(encoded)\n",
    "    decoded = Loader.onehot_to_label(encoded)\n",
    "    print(decoded)\n",
    "\n",
    "    # mnist images serialization testcase\n",
    "    # training_data_digits = list()\n",
    "    # for i in range(10):\n",
    "    #     l = list()\n",
    "    #     l.append(i)\n",
    "\n",
    "    #     d = mnist_loader.__load_data(\n",
    "    #         dataset=\"training\",\n",
    "    #         digits=l,\n",
    "    #         path=mnist_loader.dest_folder,\n",
    "    #         asbytes=False,\n",
    "    #         selection=None,\n",
    "    #         return_labels=True,\n",
    "    #         return_indices=False)\n",
    "\n",
    "    #     Loader.saveAsPickle(\n",
    "    #         d,\n",
    "    #         os.path.join(mnist_loader.dest_folder,\n",
    "    #                      \"mnist_training_digit_\" + str(i) + \".pickle\"))\n",
    "    #     training_data_digits.append(d)\n",
    "\n",
    "    # serialize svhn images into pickle format\n",
    "    # for i in range(10):\n",
    "\n",
    "    #     d = svhn_loader.__load_data('training', digits=i)\n",
    "\n",
    "    #     Loader.saveAsPickle(\n",
    "    #         d,\n",
    "    #         os.path.join(svhn_loader.dest_folder,\n",
    "    #                      \"svhn_training_digit_\" + str(i) + \".pickle\"))\n",
    "\n",
    "    # for i in range(0, 10):\n",
    "\n",
    "    #     da = Loader.loadPickle(\n",
    "    #         os.path.join(svhn_loader.dest_folder, \"svhn_training_digit_\" + str(\n",
    "    #             i) + \".pickle\"))\n",
    "    #     # svhn_loader.validate_data(da)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "----\n",
    "## Step 2: Train a Model on a Realistic Dataset\n",
    "Once you have settled on a good architecture, you can train your model on real data. In particular, the [Street View House Numbers (SVHN)](http://ufldl.stanford.edu/housenumbers/) dataset is a good large-scale dataset collected from house numbers in Google Street View. Training on this more challenging dataset, where the digits are not neatly lined-up and have various skews, fonts and colors, likely means you have to do some hyperparameter exploration to perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import gc\n",
    "import math\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from data_loader import MNISTLoader, SVHNLoader\n",
    "from image_process import ImageProcess\n",
    "\n",
    "_DEBUG = True\n",
    "\n",
    "\n",
    "def _log(message, end='\\r\\n'):\n",
    "    if _DEBUG:\n",
    "        print(message, end=end)\n",
    "\n",
    "\n",
    "class CNNTrainer:\n",
    "\n",
    "    train_name = 'convolution_neural_networks_train'\n",
    "    summary_dirname = None\n",
    "    ckpt_saver = None\n",
    "    ckpt_fname = None\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        return\n",
    "\n",
    "    def weight_variable(self, shape, name=None, kstddev = None):\n",
    "        \"\"\"\n",
    "        Initialize weight variables\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        shape : list\n",
    "            weight variable's shape\n",
    "        name : str\n",
    "            tensorflow graph's name\n",
    "        kstddev: int\n",
    "            if you want to customize stddev up to image size, pass the size using this parameter\n",
    "            normally you can use image's W * H * depth or labels' distinct encoding\n",
    "            from https://arxiv.org/pdf/1502.01852v1.pdf\n",
    "\n",
    "\n",
    "        Returns\n",
    "        ------\n",
    "        tf.Variable\n",
    "        \"\"\"\n",
    "\n",
    "        name = '%s_w' % name if not name else None\n",
    "        stddev = None if kstddev is None else math.sqrt(2.0 / kstddev)\n",
    "\n",
    "        return tf.Variable(tf.truncated_normal(shape, stddev=0.1),\n",
    "                           dtype=tf.float32,\n",
    "                           name=name)\n",
    "\n",
    "    def bias_variable(self, shape, name=None):\n",
    "        name = '%s_b' % name if not name else None\n",
    "\n",
    "        return tf.Variable(tf.zeros(shape),\n",
    "                           dtype=tf.float32,\n",
    "                           name=name)\n",
    "\n",
    "    def conv2d(self, x, W, strides=[1,1,1,1], padding='SAME'):\n",
    "\n",
    "        strides = strides\n",
    "        padding = padding\n",
    "\n",
    "        return tf.nn.conv2d(x, W,\n",
    "                            strides=strides,\n",
    "                            padding=padding)\n",
    "\n",
    "    def max_pool_2x2(self, x):\n",
    "        return tf.nn.max_pool(x,\n",
    "                              ksize=[1, 2, 2, 1],\n",
    "                              strides=[1, 2, 2, 1],\n",
    "                              padding='SAME')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class SVHNTrainer(CNNTrainer):\n",
    "    tf_x = None\n",
    "    tf_y_ = None\n",
    "\n",
    "    tf_keep_prob = None\n",
    "    tf_l2_beta = None\n",
    "\n",
    "    train_dataset = None\n",
    "    test_dataset = None\n",
    "\n",
    "    tf_optimizer = None\n",
    "    tf_accuracy = None\n",
    "    tf_loss = None\n",
    "\n",
    "    raw_image_shape = None\n",
    "    image_shape = None\n",
    "    label_shape = None\n",
    "\n",
    "    is_model_initialized = False\n",
    "\n",
    "    tf_debug1 = None\n",
    "    tf_debug2 = None\n",
    "    tf_debug3 = None\n",
    "    tf_debug4 = None\n",
    "\n",
    "    seed = 42\n",
    "    pred_value = None\n",
    "\n",
    "\n",
    "    def __init__(self, image_shape=[None, 32, 32, 3], label_shape=[None, 10], train_name=None):\n",
    "\n",
    "        # set image, label shape\n",
    "        self.image_shape = image_shape\n",
    "        self.label_shape = label_shape\n",
    "        self.raw_image_shape = self.image_shape if image_shape[3] != 1 else image_shape[0:3]\n",
    "\n",
    "        _log('input shape must be ', end='')\n",
    "        _log(self.raw_image_shape)\n",
    "\n",
    "        # set tf variables for input, labels and hyper-parameters\n",
    "        self.tf_x = tf.placeholder(tf.float32, self.raw_image_shape)\n",
    "        self.tf_y_ = tf.placeholder(tf.float32, self.label_shape)\n",
    "\n",
    "        self.tf_learning_rate = tf.placeholder(tf.float32)\n",
    "        self.tf_l2_beta = tf.placeholder(tf.float32)\n",
    "\n",
    "        self.tf_keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "        # set this trainer name\n",
    "        self.train_name = train_name if train_name else self.train_name\n",
    "        self.ckpt_fname = './ckpt/%s.ckpt' % self.train_name\n",
    "        self.summary_dirname = './summary/%s/' % self.train_name\n",
    "\n",
    "        return\n",
    "\n",
    "    def set_model(self):\n",
    "        self.is_model_initialized = True\n",
    "\n",
    "        x_input = tf.reshape(self.tf_x, [-1] + self.image_shape[1:4])\n",
    "\n",
    "        # convolution vector definition\n",
    "        w_conv1 = self.weight_variable([5, 5, 3, 16], name='conv1')\n",
    "        b_conv1 = self.bias_variable([16], name='conv1')\n",
    "\n",
    "        w_conv2 = self.weight_variable([5, 5, 16, 32], name='conv2')\n",
    "        b_conv2 = self.bias_variable([32], name='conv2')\n",
    "\n",
    "        w_conv3 = self.weight_variable([5, 5, 32, 64], name='conv3')\n",
    "        b_conv3 = self.bias_variable([64], name='conv3')\n",
    "\n",
    "        w_conv4 = self.weight_variable([5, 5, 64, 128], name='conv4')\n",
    "        b_conv4 = self.bias_variable([128], name='conv4')\n",
    "\n",
    "        w_fc1 = self.weight_variable([4 * 4 * 128, 256], name='fc1')\n",
    "        b_fc1 = self.bias_variable([256], name='fc1')\n",
    "\n",
    "        w_fc2 = self.weight_variable([256, 128], name='fc2')\n",
    "        b_fc2 = self.bias_variable([128], name='fc2')\n",
    "\n",
    "        # weight & bias matrix depends on features\n",
    "        w_fc2_len = self.weight_variable([128, 10], name='fc2_len')\n",
    "        b_fc2_len = self.bias_variable([10], name='fc2_len')\n",
    "\n",
    "        w_fc2_d1 = self.weight_variable([128, 10], name='fc2_d1')\n",
    "        b_fc2_d1 = self.bias_variable([10], name='fc2_d1')\n",
    "\n",
    "        w_fc2_d2 = self.weight_variable([128, 10], name='fc2_d2')\n",
    "        b_fc2_d2 = self.bias_variable([10], name='fc2_d2')\n",
    "\n",
    "        w_fc2_d3 = self.weight_variable([128, 10], name='fc2_d3')\n",
    "        b_fc2_d3 = self.bias_variable([10], name='fc2_d3')\n",
    "\n",
    "        w_fc2_d4 = self.weight_variable([128, 10], name='fc2_d4')\n",
    "        b_fc2_d4 = self.bias_variable([10], name='fc2_d4')\n",
    "\n",
    "        w_fc2_d5 = self.weight_variable([128, 10], name='fc2_d5')\n",
    "        b_fc2_d5 = self.bias_variable([10], name='fc2_d5')\n",
    "\n",
    "        w_fc2_d6 = self.weight_variable([128, 10], name='fc2_d6')\n",
    "        b_fc2_d6 = self.bias_variable([10], name='fc2_d6')\n",
    "\n",
    "        # set up saver for continuous learning\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/train/Saver\n",
    "        param_lst = [w_conv1, w_conv2, w_conv3, w_conv4, w_fc1, w_fc2,]\n",
    "        param_lst += [b_conv1, b_conv2, b_conv3, b_conv4, b_fc1, b_fc2,]\n",
    "        param_lst += [w_fc2_len, w_fc2_d1, w_fc2_d2, w_fc2_d3, w_fc2_d4, w_fc2_d5, w_fc2_d6, ]\n",
    "        param_lst += [b_fc2_len, b_fc2_d1, b_fc2_d2, b_fc2_d3, b_fc2_d4, b_fc2_d5, b_fc2_d6, ]\n",
    "\n",
    "        self.ckpt_saver = tf.train.Saver(param_lst)\n",
    "\n",
    "        # convolution layer\n",
    "        with tf.name_scope('hidden_layer1') as hl_scope1:\n",
    "            h_conv1 = tf.nn.relu(self.conv2d(x_input, w_conv1) + b_conv1)\n",
    "            h_pool1 = self.max_pool_2x2(h_conv1)\n",
    "\n",
    "        with tf.name_scope('hidden_layer2') as hl_scope2:\n",
    "            h_conv2 = tf.nn.relu(self.conv2d(h_pool1, w_conv2) + b_conv2)\n",
    "            h_pool2 = self.max_pool_2x2(h_conv2)\n",
    "\n",
    "        with tf.name_scope('hidden_layer3') as hl_scope3:\n",
    "            h_conv3 = tf.nn.relu(self.conv2d(h_pool2, w_conv3) + b_conv3)\n",
    "            h_pool3 = self.max_pool_2x2(h_conv3)\n",
    "\n",
    "        with tf.name_scope('hidden_layer4') as hl_scope4:\n",
    "            h_conv4 = tf.nn.relu(self.conv2d(h_pool3, w_conv4) + b_conv4)\n",
    "            h_pool4 = self.max_pool_2x2(h_conv4)\n",
    "\n",
    "        # fully connected layer\n",
    "        with tf.name_scope('fully_connected_layer1') as fc_scope1:\n",
    "            shape  = h_pool4.get_shape().as_list()\n",
    "            h_pool4_flat = tf.reshape(h_pool4, [-1, shape[1] * shape[2] * shape[3]])\n",
    "\n",
    "            h_pool4_flat_dropout = tf.nn.dropout(h_pool4_flat, self.tf_keep_prob, seed=self.seed)\n",
    "            h_fc1 = tf.nn.relu(tf.matmul(h_pool4_flat_dropout, w_fc1) + b_fc1)\n",
    "\n",
    "        # dropout\n",
    "        with tf.name_scope('fully_connected_layer2') as fc_scope2:\n",
    "            h_fc1_dropout = tf.nn.dropout(h_fc1, self.tf_keep_prob, seed=self.seed)\n",
    "            h_fc2 = tf.nn.relu(tf.matmul(h_fc1_dropout, w_fc2)+b_fc2)\n",
    "\n",
    "        # readout layer\n",
    "        with tf.name_scope('readout_layer') as ro_scope:\n",
    "            pred_r_len = tf.matmul(h_fc2, w_fc2_len) + b_fc2_len\n",
    "            pred_len = tf.reshape(pred_r_len, [-1,10])\n",
    "\n",
    "            pred_r_d1 = tf.matmul(h_fc2, w_fc2_d1) + b_fc2_d1\n",
    "            pred_d1 = tf.reshape(pred_r_d1, [-1,10])\n",
    "\n",
    "            pred_r_d2 = tf.matmul(h_fc2, w_fc2_d2) + b_fc2_d2\n",
    "            pred_d2 = tf.reshape(pred_r_d2, [-1,10])\n",
    "\n",
    "            pred_r_d3 = tf.matmul(h_fc2, w_fc2_d3) + b_fc2_d3\n",
    "            pred_d3 = tf.reshape(pred_r_d3, [-1,10])\n",
    "\n",
    "            pred_r_d4 = tf.matmul(h_fc2, w_fc2_d4) + b_fc2_d4\n",
    "            pred_d4 = tf.reshape(pred_r_d4, [-1,10])\n",
    "\n",
    "            pred_r_d5 = tf.matmul(h_fc2, w_fc2_d5) + b_fc2_d5\n",
    "            pred_d5 = tf.reshape(pred_r_d5, [-1,10])\n",
    "\n",
    "            pred_r_d6 = tf.matmul(h_fc2, w_fc2_d6) + b_fc2_d6\n",
    "            pred_d6 = tf.reshape(pred_r_d6, [-1,10])\n",
    "\n",
    "        # loss calculation\n",
    "        with tf.name_scope('loss_calculation') as lc_scope:\n",
    "            softmax_len = tf.nn.softmax_cross_entropy_with_logits(labels=tf.reshape(self.tf_y_, (-1,7,10))[:,0,:],\n",
    "                                                                  logits=pred_len)\n",
    "            softmax_d1 = tf.nn.softmax_cross_entropy_with_logits(labels=tf.reshape(self.tf_y_, (-1,7,10))[:,1,:],\n",
    "                                                                  logits=pred_d1)\n",
    "            softmax_d2 = tf.nn.softmax_cross_entropy_with_logits(labels=tf.reshape(self.tf_y_, (-1,7,10))[:,2,:],\n",
    "                                                                  logits=pred_d2)\n",
    "            softmax_d3 = tf.nn.softmax_cross_entropy_with_logits(labels=tf.reshape(self.tf_y_, (-1,7,10))[:,3,:],\n",
    "                                                                  logits=pred_d3)\n",
    "            softmax_d4 = tf.nn.softmax_cross_entropy_with_logits(labels=tf.reshape(self.tf_y_, (-1,7,10))[:,4,:],\n",
    "                                                                  logits=pred_d4)\n",
    "            softmax_d5 = tf.nn.softmax_cross_entropy_with_logits(labels=tf.reshape(self.tf_y_, (-1,7,10))[:,5,:],\n",
    "                                                                  logits=pred_d5)\n",
    "            softmax_d6 = tf.nn.softmax_cross_entropy_with_logits(labels=tf.reshape(self.tf_y_, (-1,7,10))[:,6,:],\n",
    "                                                                  logits=pred_d6)\n",
    "\n",
    "            regularization = tf.nn.l2_loss(w_fc1) + tf.nn.l2_loss(b_fc1)\n",
    "            self.tf_loss = self.tf_l2_beta * regularization\n",
    "            self.tf_loss += tf.reduce_mean(softmax_len)\n",
    "            self.tf_loss += tf.reduce_mean(softmax_d1)\n",
    "            self.tf_loss += tf.reduce_mean(softmax_d2)\n",
    "            self.tf_loss += tf.reduce_mean(softmax_d3)\n",
    "            self.tf_loss += tf.reduce_mean(softmax_d4)\n",
    "            self.tf_loss += tf.reduce_mean(softmax_d5)\n",
    "            # self.tf_loss += tf.reduce_mean(softmax_d6)\n",
    "\n",
    "            tf.summary.scalar('loss', self.tf_loss)\n",
    "\n",
    "        # loss optimizer\n",
    "        with tf.name_scope('training') as tr_scope:\n",
    "            self.tf_optimizer = tf.train.AdamOptimizer(learning_rate=self.tf_learning_rate).minimize(self.tf_loss)\n",
    "\n",
    "        # accuracy calculation\n",
    "        with tf.name_scope('accuracy_calculation') as acc_scope:\n",
    "            pred_combined = tf.stack([pred_len, pred_d1, pred_d2, pred_d3, pred_d4, pred_d5, pred_d6], axis=1)\n",
    "            predict = tf.reshape(pred_combined, (-1, 7, 10))\n",
    "            is_correct_pred = tf.equal(\n",
    "                tf.argmax(predict, 2), tf.argmax(tf.reshape(self.tf_y_, (-1,7,10)), 2))\n",
    "            self.tf_accuracy = tf.reduce_mean(tf.cast(is_correct_pred, tf.float32))\n",
    "            tf.summary.scalar('accuracy', self.tf_accuracy)\n",
    "\n",
    "            self.pred_value = tf.argmax(predict, 2)\n",
    "\n",
    "\n",
    "    def train(self, for_training=True):\n",
    "        if not self.is_model_initialized:\n",
    "            raise AssertionError('you must initilize model using set_model function')\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            # Batching data\n",
    "            batch_size = 50\n",
    "            train_size = self.train_dataset[0].shape[0]\n",
    "\n",
    "            # hyper-parameters\n",
    "            learning_rate = 3.1e-4\n",
    "            l2_beta = 16e-4\n",
    "            keep_prob = 0.5\n",
    "\n",
    "            feed_train = None\n",
    "            feed_accu = None\n",
    "            feed_test = None\n",
    "\n",
    "            if for_training:\n",
    "                # generate tensorflow summary merged\n",
    "                merged = tf.summary.merge_all()\n",
    "                train_writer = tf.summary.FileWriter(self.summary_dirname, sess.graph)\n",
    "\n",
    "                _log('we\\'re about to training using %d trainset...' % self.train_dataset[0].shape[0])\n",
    "                _log('trainset size : {:4d}'.format(train_size))\n",
    "                _log('batch    size : {:4d}'.format(batch_size))\n",
    "\n",
    "                _log('. : 1 training epoch')\n",
    "\n",
    "                for epoch in range(450):\n",
    "\n",
    "                    # Shuffling the train sets\n",
    "                    indices = np.random.permutation(range(self.train_dataset[0].shape[0]))\n",
    "                    for i, _ in enumerate(self.train_dataset):\n",
    "                        self.train_dataset[i] = self.train_dataset[i][indices]\n",
    "\n",
    "                    # batch_ training\n",
    "                    for batch_step in range(0, train_size, batch_size):\n",
    "\n",
    "                        batch = [\n",
    "                            self.train_dataset[0][batch_step:batch_step+batch_size],\n",
    "                            self.train_dataset[4][batch_step:batch_step+batch_size],\n",
    "                            self.train_dataset[1][batch_step:batch_step+batch_size]]\n",
    "\n",
    "                        # Check batch images for the training\n",
    "                        if False:\n",
    "                            fig = plt.figure(figsize=(12, 1), dpi=80)\n",
    "\n",
    "                            for i in range(12):\n",
    "                                plt.subplot(1, 12, i+1)\n",
    "                                plt.title(batch[2][i])\n",
    "                                plt.imshow(batch[0][i,:,:].reshape(64, 64, 3),\n",
    "                                           interpolation='nearest')\n",
    "                                plt.tight_layout()\n",
    "\n",
    "                            plt.show()\n",
    "\n",
    "                        feed_train ={self.tf_x: batch[0],\n",
    "                                     self.tf_y_: batch[1],\n",
    "                                     self.tf_learning_rate: learning_rate,\n",
    "                                     self.tf_l2_beta: l2_beta,\n",
    "                                     self.tf_keep_prob: keep_prob}\n",
    "\n",
    "                        feed_accu ={self.tf_x: batch[0],\n",
    "                                     self.tf_y_: batch[1],\n",
    "                                     self.tf_learning_rate: learning_rate,\n",
    "                                     self.tf_l2_beta: l2_beta,\n",
    "                                     self.tf_keep_prob: 1.0}\n",
    "\n",
    "                        # Do training\n",
    "                        self.tf_optimizer.run(feed_dict=feed_train)\n",
    "\n",
    "                    # tensorflow logging for tensorboard\n",
    "                    _summaries = sess.run(merged, feed_dict=feed_train)\n",
    "                    train_writer.add_summary(_summaries, epoch)\n",
    "\n",
    "                    # save model weights and biases\n",
    "                    self.ckpt_saver.save(sess, self.ckpt_fname)\n",
    "\n",
    "                    # logging loss and accuracy\n",
    "                    print(\".\", end='')\n",
    "                    if not epoch % 20:\n",
    "                        _loss, _train_accuracy = sess.run([self.tf_loss, self.tf_accuracy],\n",
    "                                                          feed_dict=feed_accu)\n",
    "\n",
    "                        print('')\n",
    "                        print(\"epoch {:4d} -> loss : {:05.2f} / training_accuracy: {:05.2f}\".format(\n",
    "                            epoch, _loss, _train_accuracy))\n",
    "\n",
    "                        if _loss < 5. and _train_accuracy > 0.8:\n",
    "                            break \n",
    "\n",
    "            self.ckpt_saver.restore(sess, self.ckpt_fname)\n",
    "\n",
    "            feed_test = {self.tf_x: self.test_dataset[0],\n",
    "                         self.tf_y_: self.test_dataset[4],\n",
    "                         self.tf_learning_rate: learning_rate,\n",
    "                         self.tf_l2_beta: l2_beta,\n",
    "                         self.tf_keep_prob: 1.0}\n",
    "\n",
    "            print('testing accuracy {:05.2f}'.format(self.tf_accuracy.eval(feed_dict=feed_test)))\n",
    "        return\n",
    "\n",
    "\n",
    "    def predict(self, test_dataset):\n",
    "        if not self.is_model_initialized:\n",
    "            raise AssertionError('you must initilize model using set_model function')\n",
    "\n",
    "        label = np.zeros(test_dataset.shape[0] * 70).reshape(-1, 70)\n",
    "        pred = None\n",
    "\n",
    "        # hyper-parameters\n",
    "        learning_rate = 3.1e-4\n",
    "        l2_beta = 16e-4\n",
    "        keep_prob = 0.5\n",
    "\n",
    "        feed_train = None\n",
    "        feed_accu = None\n",
    "        feed_test = None        \n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            self.ckpt_saver.restore(sess, self.ckpt_fname)\n",
    "\n",
    "            # hyper-parameters\n",
    "            learning_rate = 3.1e-4\n",
    "            l2_beta = 16e-4\n",
    "\n",
    "            feed_test = {self.tf_x: test_dataset,\n",
    "                         self.tf_y_: label,\n",
    "                         self.tf_learning_rate: learning_rate,\n",
    "                         self.tf_l2_beta: l2_beta,\n",
    "                         self.tf_keep_prob: 1.0}\n",
    "\n",
    "            pred = sess.run(self.pred_value,\n",
    "                            feed_dict=feed_test)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_for_svhn_synthetic():\n",
    "    loader = SVHNLoader()\n",
    "    loader.init_data()\n",
    "\n",
    "    trainer = SVHNTrainer([None, 64, 64, 3], [None, 70], train_name='svhn_synthetic')\n",
    "\n",
    "    _log('data loading...', end='\\r\\n')\n",
    "\n",
    "    trainer.train_dataset = list(loader.get_mixed_data(\"training\"))\n",
    "    trainer.test_dataset = list(loader.get_mixed_data(\"testing\"))\n",
    "\n",
    "    train_L = np.c_[trainer.train_dataset[3]+1, trainer.train_dataset[2]]\n",
    "    train_L_1hot = np.array([[loader.label_to_onehot(digit)] for digit in train_L.T])\n",
    "    train_L_1hot = np.transpose(train_L_1hot, (1,2,0,3))\n",
    "    train_L_1hot = train_L_1hot.reshape((-1, 7 * 10))\n",
    "\n",
    "    test_L = np.c_[trainer.test_dataset[3]+1, trainer.test_dataset[2]]\n",
    "    test_L_1hot = np.array([[loader.label_to_onehot(digit)] for digit in test_L.T])\n",
    "    test_L_1hot = np.transpose(test_L_1hot, (1,2,0,3))\n",
    "    test_L_1hot = test_L_1hot.reshape((-1, 7 * 10))\n",
    "\n",
    "    trainer.train_dataset.append(train_L_1hot)\n",
    "    trainer.test_dataset.append(test_L_1hot)\n",
    "\n",
    "    _log('data validation...', end='\\r\\n')\n",
    "\n",
    "    # To check image input\n",
    "    _log('input image data shape : ', end='')\n",
    "    _log(trainer.train_dataset[0].shape)\n",
    "\n",
    "    # To check label input\n",
    "    _log('input label data shape : ', end='')\n",
    "    _log(trainer.train_dataset[1].shape)\n",
    "\n",
    "    _log('training...')\n",
    "    trainer.set_model()\n",
    "    trainer.train(for_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape must be [None, 64, 64, 3]\n",
      "data loading...\n",
      "data validation...\n",
      "input image data shape : (5000, 64, 64, 3)\n",
      "input label data shape : (5000,)\n",
      "training...\n",
      "we're about to training using 5000 trainset...\n",
      "trainset size : 5000\n",
      "batch    size :   50\n",
      ". : 1 training epoch\n",
      ".\n",
      "epoch    0 -> loss : 41.99 / training_accuracy: 00.29\n",
      "....................\n",
      "epoch   20 -> loss : 11.50 / training_accuracy: 00.45\n",
      "....................\n",
      "epoch   40 -> loss : 10.50 / training_accuracy: 00.47\n",
      "....................\n",
      "epoch   60 -> loss : 10.59 / training_accuracy: 00.44\n",
      "....................\n",
      "epoch   80 -> loss : 08.80 / training_accuracy: 00.49\n",
      "....................\n",
      "epoch  100 -> loss : 07.37 / training_accuracy: 00.54\n",
      "....................\n",
      "epoch  120 -> loss : 07.16 / training_accuracy: 00.51\n",
      "....................\n",
      "epoch  140 -> loss : 07.07 / training_accuracy: 00.47\n",
      "....................\n",
      "epoch  160 -> loss : 06.02 / training_accuracy: 00.53\n",
      "....................\n",
      "epoch  180 -> loss : 06.25 / training_accuracy: 00.55\n",
      "....................\n",
      "epoch  200 -> loss : 04.37 / training_accuracy: 00.66\n",
      "....................\n",
      "epoch  220 -> loss : 03.99 / training_accuracy: 00.69\n",
      "....................\n",
      "epoch  240 -> loss : 04.48 / training_accuracy: 00.67\n",
      "....................\n",
      "epoch  260 -> loss : 03.49 / training_accuracy: 00.72\n",
      "....................\n",
      "epoch  280 -> loss : 03.00 / training_accuracy: 00.72\n",
      "....................\n",
      "epoch  300 -> loss : 03.58 / training_accuracy: 00.69\n",
      "....................\n",
      "epoch  320 -> loss : 02.60 / training_accuracy: 00.76\n",
      "....................\n",
      "epoch  340 -> loss : 02.00 / training_accuracy: 00.79\n",
      "....................\n",
      "epoch  360 -> loss : 02.84 / training_accuracy: 00.73\n",
      "....................\n",
      "epoch  380 -> loss : 02.44 / training_accuracy: 00.76\n",
      "....................\n",
      "epoch  400 -> loss : 02.04 / training_accuracy: 00.79\n",
      "....................\n",
      "epoch  420 -> loss : 01.80 / training_accuracy: 00.81\n",
      "testing accuracy 00.48\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # train_for_mnist_normal()\n",
    "    # train_for_mnist_synthetic()\n",
    "    train_for_svhn_synthetic()\n",
    "    # predict_real_image_using_svhn()\n",
    "    \n",
    "    gc.collect()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Question 4\n",
    "_Describe how you set up the training and testing data for your model. How does the model perform on a realistic dataset?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The method of creating the data was the one that was processed using the existing MNIST data.\n",
    "\n",
    "It is a method to randomly select images corresponding to each digit by randomizing 5 digits using random numbers provided by SVHN.\n",
    "\n",
    "And in this process, the actual data randomly changed the starting position of the image, considering that the position of the number of the image usually changes every time.\n",
    "\n",
    "The difference from MNIST is that in the case of SVHN, the dataset was a MATLAB file, so it was created using the loadmat function provided by Scipy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Question 5\n",
    "_What changes did you have to make, if any, to achieve \"good\" results? Were there any options you explored that made the results worse?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "I have tried to change a little bit but the results do not get much better, so I submit the task with the current result.\n",
    "\n",
    "This challenge seems to be a challenge that is easy for me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Question 6\n",
    "_What were your initial and final results with testing on a realistic dataset? Do you believe your model is doing a good enough job at classifying numbers correctly?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "When I first experimented with SVHN datasets, I thought I got good results. However, this was the result of a bug in how Accuracy was measured. : '- (\n",
    "\n",
    "Unlike MNIST, the performance was not better than expected. I think there is a problem with the model at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "----\n",
    "## Step 3: Test a Model on Newly-Captured Images\n",
    "\n",
    "Take several pictures of numbers that you find around you (at least five), and run them through your classifier on your computer to produce example results. Alternatively (optionally), you can try using OpenCV / SimpleCV / Pygame to capture live images from a webcam and run those through your classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_real_image_using_svhn():\n",
    "    trainer = SVHNTrainer([None, 64, 64, 3], [None, 70], train_name='svhn_synthetic')\n",
    "    _log('data loading...', end='\\r\\n')\n",
    "\n",
    "    _log('testring for real dataset...')\n",
    "    fname_list = [\n",
    "        os.path.join('./KR_data', 'IMG_20170315_201204260.jpg'),\n",
    "        os.path.join('./KR_data', 'IMG_20170315_201212453.jpg'),\n",
    "        os.path.join('./KR_data', 'IMG_20170315_201232407_BURST000_COVER_TOP.jpg'),\n",
    "        os.path.join('./KR_data', 'IMG_20170315_201232407_BURST001.jpg'),\n",
    "        os.path.join('./KR_data', 'IMG_20170315_203000566.jpg'),\n",
    "    ]\n",
    "\n",
    "    ip = ImageProcess()\n",
    "    img = np.array([ip.processImage(fname) for fname in fname_list])\n",
    "\n",
    "    _log('predict...')\n",
    "    trainer.set_model()\n",
    "    print(trainer.predict(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape must be [None, 64, 64, 3]\n",
      "data loading...\n",
      "testring for real dataset...\n",
      "./KR_data/IMG_20170315_201204260.jpg is loading...\n",
      "./KR_data/IMG_20170315_201212453.jpg is loading...\n",
      "./KR_data/IMG_20170315_201232407_BURST000_COVER_TOP.jpg is loading...\n",
      "./KR_data/IMG_20170315_201232407_BURST001.jpg is loading...\n",
      "./KR_data/IMG_20170315_203000566.jpg is loading...\n",
      "predict...\n",
      "[[3 7 8 0 0 0 1]\n",
      " [3 7 8 0 0 0 1]\n",
      " [3 7 8 0 0 0 1]\n",
      " [3 7 8 0 0 0 1]\n",
      " [3 7 8 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # train_for_mnist_normal()\n",
    "    # train_for_mnist_synthetic()\n",
    "    # train_for_svhn_synthetic()\n",
    "    predict_real_image_using_svhn()\n",
    "    \n",
    "    gc.collect()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testring for real dataset...\n",
      "./KR_data/IMG_20170315_201204260.jpg is loading...\n",
      "./KR_data/IMG_20170315_201212453.jpg is loading...\n",
      "./KR_data/IMG_20170315_201232407_BURST000_COVER_TOP.jpg is loading...\n",
      "./KR_data/IMG_20170315_201232407_BURST001.jpg is loading...\n",
      "./KR_data/IMG_20170315_203000566.jpg is loading...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztfXmcZFdZ9nPq1t579+zTsyUzmSwz2RhDIvkgBIIQIqBi\nBFSixi+gQaOIkIBoEJEAAsInolGQqAkJEISAitlBAZMM2WbPLJm9Z3qW7umttnvrfH9UzT3P+3ZX\nT4dkapJfnef3m9+c6nPq3nPPvafuuz6vsdbCw8OjtZA41RPw8PBoPvzG9/BoQfiN7+HRgvAb38Oj\nBeE3vodHC8JvfA+PFoTf+B4eLYjntfGNMa83xmwxxmwzxtz4Qk3Kw8Pj5ML8tAE8xpgAwDMArgCw\nF8BjAN5urd34wk3Pw8PjZCD5PL57EYBt1todAGCMuRPAmwE03Pj5jk7b1Ten9sEY0cc/QGaavkTC\n9RnIceBxRgozVf6B469ZdQzxUf4o8ryq1WrDczX6zhSd8nPVTtmnf5xNgr8njyHmlXDzmvQDz+ud\nSDTss2h8X8S5bVX08Ln5stSSivtZVcfg4/O5p3s+9GXyUEP3idcJAOQtlMcXj8s0L0r5HDR+dibB\ncpOvxTYahkDds6gaAQCOHhzA2MjQNCer4fls/IUA9tDnvQBePt0Xuvrm4Df+7NMA5IMBAGEYxu0g\nSKq+Stxuy+XidtIEYlwURXE7n8qLvmKlELdNwh3fRnKNqGvSwxGkUnG7UHDHy6WzYhw/bZl0WnRV\naY7JpLrOMvWlXF+hUhbjsll3vqqV61gqldy8Mhl37EokxvFaZbLphn02cmsfpDJinPghDOUcczTH\ncuQe2WokH+Zszh2zWCzK4wfu/ibTblxgGv/YlSvqniX5Xrhnh+8fAKQybh2N0oANbcBKpSL6+B5m\nU24dE2rTJtJunInkHKv0y1ixbu31uUIa19XRLvpGRkYAAJ967zswE5x0454x5jpjzFpjzNqJsZGT\nfToPD48Z4Pm88fcBWESf++t/E7DW3grgVgCYvXCxPbS/JiRk1ZswRa9aU5W/luLtV3S/1An5whe/\nsmEwLI+fobcy/eCm1TxAb480SRcAEJCE0ZbuiNuZvHzjJ2hcIiknyedLKJEymXEShbXumpPqGHl6\nm1r19iuU3Ju3q8PNMaGkCyHNKHUnoDct6A2Uycnr5JcaTR0AUKmwuuCOH2lJWcjRjfuExBLI99XE\nxETcLk3IN7mle1EYc+PauqREWJhw0kaVpE8ASARuIiUl2WTb3DNSLrk3dFUKWAgq7pgZ9eCWqq6P\nJeF8e4cYd2RoKG4PTYyLvkp9z1QbayICz+eN/xiAFcaYZcaYNIC3AbjneRzPw8OjSfip3/jW2tAY\n8x4A/wUgAPBla+2GF2xmHh4eJw3PR9SHtfY/APzHCzQXDw+PJuF5bfznimolRHn/EQDAMWVVZeto\nKpA6EFs3c0mnTIblMTFuZO9O9x2lp7XPnhe3M2RJnjg0KMaxRyZUCmnHrIVxu7N3TtzWHgp2w1Qi\nOY+ujq64Hak+1i0zZJHXOifbKKrKepwkGwJ7SsKSPIZJuO+VtTWddGvWn0OlQLLdwCq9u0THDEhZ\nLyvl18Dda+1FqbKO38BNCQAZ8qoUiyXRF9C8jHD3Ko8QfQwjPUeHhHo2A+PWoEj6v3ZMsvMlnZJ2\npQR5i9i1mkrL7cneqNl9faKvs7tm5Y/K8vobwYfseni0IPzG9/BoQTRV1E8kk8j29QAA8rZX9IXk\nNtIBXIZFLxK1ElGnGHdkx+64XVUSz5IzznHfIzGva+lKMe7ZJx+P28XCqOgb2r0zbi/Ou3O3zZ4j\nxuXJDZhW4nGQdWJdUrniSkWn0hTJt5XPSDcai/A6kOzoqJtzR49bY6vEaP7c1dYm+ioksiZp7YOU\nEj3RODLQRhzZ6K4zUG5FUOReUrlWLZ27Qm7KXF7Ol0V/HfQiVCa65kmRdIZUn7Jy2dF1azWjTPeC\nA5+qaLweYUWpXTSUg5MqWm3haE6lTIRDI8cngZnAv/E9PFoQfuN7eLQg/Mb38GhBNNedF0aYGKqF\n0haVHsXuvEjpKWUK/wwj972U0jm7lixxH5Qrbv8eF03c2e4SHKwyKPT298dtrWPt2OQSD7c9uTZu\n95+zWowbyzodPwgaJxKxqwyQ+mNUdvPK5mXocIrcP9oFxkk6w4MH43aoxkWkCydV8g3rj6xXTkoq\nojXW9ywgl1WG2lEkdXBDCVk6rJjnmCJdfVK2Is0xp8Ks2T5Uoe9x2DMAlMrkfkzJ+GN2t0XaTUzP\n0vi4u5+JhLQhyFBtCX4OOARbJ6ux/SKdVjHSdRtZNMM0e//G9/BoQfiN7+HRgmiqqB8kk+jongUA\n6Ew2zggrlVV2FBNKsDtFuUVYBNQ52ynKiNJZfY2gxeh5y85wx+Pc/DGZKVUl/0w2K0VPFol7tPjN\nufoBiXIq2o3dYzqSbJyyF9MBZ/gpV9w05CHsLkxRrn5WRZwNHXNp1jq6kDkDygUnRut58DWHSu0K\n4DLoWCUzKluRnxcdhZijzMmA5jg+Lu+ZIIJRLtgCuUgD9fCMsjpIWXxjYzKqNGCiB6MiIBNTcwEU\nKlLVZH6CMaUqH4/E1KpII/g3vodHC8JvfA+PFkRzrfrWolgXz1NGiXwkzuqoKrZUMtmGUYkhIjpN\nibIVipxicU1TY7HltDodFx2JWtmsJqggqqlpLNCBIuJIkDhYIjFPewaCpJtzRUeZUcJKkr5XUVb3\napUtxIoUJSALOom9Y4rkgq9bz5HFUsNWcqXeZKbx5jB5iraSM/ieaUs4g9WFUInEvAaRosbix1F7\nFJINkmq0msiH1NfJ6g9HKwZJxavHqqB6NMP68dMZ6aFpBP/G9/BoQfiN7+HRgvAb38OjBdFUHd8Y\ng0y2dsoEpE4oXHYqs4n1ZPb4BIpMIS0ixJQLjK7UErkkEyQCMhqwqhO46HeSM7hC5Z5humpT1ZQM\nDqFmlyTFLZd0riydEcY6odZVhULKbiI1j3zOHV+7T5M0D7aHJBJ6HLuo9GK5z2wL4MhCQEaqGW0n\nYN2a3X6aDJOegzCU9z2TIqIPsvtMspswVbi6lDTr4ErHZ5ruKmWYagJT/p52aVoi2+TaAoGm+Rb3\nVs7fHifgaALZpoeHx0sUfuN7eLQgmkvEkUggn62RKITKZcLiTzIlxZhiwYmHLGJP5nmnpBEVBZYj\n0ZZFJqvdXOQ2yqgIMXbRsOtGqxX5fH7K7wBAFPIxtEpDrhwmHJmmYlBvryQ0YWIIvk7t5BGVdDJK\n7OVzcymsqhzXiOSi/ocpj6fXm1212q3IzwTz5ekkmoB4GEtF6XJkdWc6kZ2vMzFJPWPVUEYGtlFF\nm6jC1aCUKM7q2iS3pVvHcYr4027t6cpwpet7wUzj9mT4N76HRwvCb3wPjxaE3/geHi2Ipur4gNOt\nAqWLBORqyWdUXbMxp7ex/jyqMqzaqa+9TVYTLZXcMZiHXbuQEkRCkc3IzDp23XAVVq3PsR1C93GI\npybHyJCuylVlE0Fjt05JkUsy2I2mq8MyptOtef7ajcbXqXX8NiLw5HE5RexZor600t1FBiTp1olA\nh3u7eeXa5LNTLk4d+qyvZboy3MJWokJi2TaQzrn56vvO0ISgxaJbgw6qd6jnIStKy+On6pmB04U2\nM074xjfGfNkYM2iMWU9/6zXG3GeM2Vr/v2dGZ/Pw8HhRYCai/lcAvF797UYAD1hrVwB4oP7Zw8Pj\nJQKj3RpTDjJmKYDvWmtX1T9vAXCZtXbAGDMfwMPW2pXTHAIA0NbWZc886xIAQFevEhIoO0/zjldJ\n5EnRdHWZrJD43NJKTI9IhG8TvOwqKo7dLipijkUtdptEirghze6rQIqv2TYq9zQuXUNZUlW4FLQW\nxTNpd22ajy9k0o6IRNRpXJ/5dnmMJF0bi9vWKnce8dvp8tfMqZgKOOJRirnsmkuqsDNWyZjr3yhR\nX9YZkMfg+fN1FRRhB2e1aTKPJJ1vdEzWWhAcf6TuVFUE4YEDB6b+DoAJOiZnBmo1Lqy4eWl1+Djx\nx/fvvwPDRw+eUN7/aY17c621A/X2AQBzf8rjeHh4nAI8b6u+rf3ENhQbjDHXGWPWGmPWhmG50TAP\nD48m4qe16h80xswnUX+w0UBr7a0AbgWA1StX2G/81Q0AJlslRSLKJPKKqaO7tCWZxTyrZE8WvNhq\nPalCKw1MGBXBRSVPOeJsEnEIHUQTYFiKzhsdlZb2Mol5x8Yc5fLEuExsOXLMiYb7SIQEgBKNHSWu\nu6Edx8S4fN55PYY08QQnilDS0rBSTUK2diuLfGHCjc3mnKU6VMQhXDpNq1bWsIrgxPmKeoHkiGpa\ne0qYRpt578aLktqcr7NclMdnb8skEg3i2eOoTEyK+qR2KEX4BCeG0bOTUhGsnFw2ovZIrDIpfsZG\n+Gnf+PcAuKbevgbAt3/K43h4eJwCzMSd91UAPwaw0hiz1xhzLYBbAFxhjNkK4LX1zx4eHi8RnFDU\nt9a+vUHXa17guXh4eDQJTY/ci5UdpRdz2aaEIspknvOQ3EEJdYwE6VWRlboOa0sJshloQsNEmsgr\npsmGStIcE0lFwEglqfQx2JaRUnoxl4zSGWiMMOTzabsquZRoDRKm8fEmlWNOTx2BVhyXerFwbyoX\nG9tbuKaBjlqbDqwy8zpqDn+hC6soRy69naW2dvtVylTi2iqiDxo6KaqPnjleq+lKm+koSsvMH/Q9\nXW4sTe7NRm74K7b+aMq/a/hYfQ+PFoTf+B4eLYimivrFAzux4VO/BQDI52QSjbXO/aPJDqocGUdS\nXSapIqBEIocUbUdJmk31zI7bhQkp5oYkrpUhj3F41Im6ZXIJFqESTyrOHRSpslMc0BUmpDjYTmuS\nIfE4raLz+oh8o6zE3vlzXCxVlY5xxhlniHFcQkqTeXR2drlzk9ivI87YtaVFYOa3r1INhVSgEk8s\nq3jycUxTmCarSIGqY1CmiDatJmZJ9Gc3WkpFQyIpHL6ia7roVr5svrREoNxtWaf+pZWrj93X7BLU\n6gJHqqbTMlmoXFclDDwRh4eHRwP4je/h0YLwG9/DowXRVB0/mUhgVj07zVhJosGuuUpK/h4x13g6\nSfpdNCLGdSbZlSXLFM9vd5easU5Xj3JSR85liUBCZWmZ2USUycSNkGCez4TSaQOuH6DKIEuS0cZ8\n/KZA4aUVOS61z+muuU6nu4f/fbc8BtXOC1WYZ5psJ9WE6xspyFDWZIpIRZVuydmL5bJbx4rm8BdE\novL4XOtO1BJQ2ZDJrAsJtooUP4iG3Lmp9l93R6cYxy7CqgrVDquNQ3YjWke+f0FG2hD4mYjUtiuT\n264auu+NF+UzbOh7NlDzD2r7oji4CzOBf+N7eLQg/Mb38GhBNFXUHw768Z22jwMA2vPSBZZrcyJa\nR48iZCBx+c2XObHrmVt+QYyLrBOZ8jnFJE+ZTSVy++kS12USB8cnpDrS0elEW45Am/WmPxXj5pz3\nKjeurLKlLHHAqdJbiSqRTcCNG7zjQ2IcB6eFKrqLawGI7MI2KXoa4z4XVEReYMgdSdeZz8j3RDpP\nomdSrreNSOxNu3vdMQ0hiFHuPMvqQtV9L2Pkmh7evs6dqyrXoyPtjtGVd3OMQnnNorS5ViVIPauU\n5DPBJboCvpaSnGNXuxPNxxT3fztF5BWq7vhZtd783GZScq0q4Wh9DjOLjPRvfA+PFoTf+B4eLYim\nivoTYwZPPFK3PipCBk6ggEqwSZNY87pXkQVXWVg5sixSZA1pKnllSDwrl6TYlSKRNafUhUhmjcTN\nkTFpff2dXxuO22EkrcxJSr7JZlX0WNXN8Z//dUXcrowPi2FsBdaVdEsUbJjNuOOVJhTHHK13Ulmx\n0xR1V5mmEq0pu7WLxuUaRKRapZjWWrF8V5iiWz2OnCzEZdRCpRK0dblIzMrIgOjjefAxMlLjEBF/\nRlVynlA07vL4zLNHiUkqOm/4mPMuBDrqruDUDvYuBKribp6e26Ky+FePPzsz4NAE/Bvfw6Ml4Te+\nh0cLwm98D48WRFN1/CCRREe+xqcfhVJvqpL+bBRpBHM3FEivTysdPEExdFaRKYTkVkuSzhmkdCaW\n+15yEvkjldcmjvl5F71FjCt93nGPJlWWYESRZeWSKpNNpaBu/YfdcftKZScwpEuWIqk0ZynKrEgk\nmpWSdPNwBFpCuYDKtOBsR0mp8lGCsEKV0I4oorCcdhmDC9/4LjFu7Khbq2hI2jImRt0zki+5KM3x\ngzvkPCiCc6KkypKT7zNDmZKmomxMFGmnSUtyne66KxPKzpHmsVNnkdYn6eYUyWeTw/rSFLWqsxUr\nXGJd2RCi+liTmNm73L/xPTxaEH7je3i0IJoq6lerEQoTNX73lCLR4LJZOnIqReLy4UFyy00o31CK\nSz8pAgxyRbGQZJVoxNxx1aribyN+vvk33BO333ntUTGOq7kKFyCkKpFQiRwBiW8PPujW4B1/810x\n7uitV8btVEJF/3GJMeJ54yQXAIhI1E0ot2iFeA2Z+i9SfHlM+hCkFbcguZWS5/1K3H7XLWvEOE7u\nYd772gmIa7Hi3Ffv+WNZfi2TcteZTcr15kjGfM6dqy2vKgST2zLVJo9/zTtc4ktVqV3sTjWgqr0Z\nuab/cPWX4/bAk/8u+soldy+4LFmpQxaouvnRv4/bI6omQ6ZeqXd/8XcwE/g3vodHC8JvfA+PFoTf\n+B4eLYim6vgmASRztd+aSkm6I5iPgcsZA5KQ4TvfeCJuX53VIbVO19OhrCBiy4h+76xyQx1CX9xe\n8/6vir4//oCrWbf/GgqZVK6VsMQ6snQNiWy0hOZ2J+JJ6vutdx8W4xbN/pe4/blPy+Mf/Lt3xu1o\nwoWCVrQLqdqY1JH14gqH6SYUiQbVlCsrd2E65TLy8itXxW1r5D3j45e1PYTJSOh7n/2UdPvx/Cuq\n7l25xASVxKuvnjHO3oyiQ7KL694pHT9NtpMgSTampFyPgxsfdMdQBKmGnseIiEpyq94sxpV+5O5L\nJiuJOCbqGZbRzErnzaiE1iJjzEPGmI3GmA3GmBvqf+81xtxnjNla/7/nRMfy8PB4cWAmon4I4I+s\ntWcDuBjA9caYswHcCOABa+0KAA/UP3t4eLwEMJPaeQMABurtUWPMJgALAbwZwGX1YbcBeBjAB6Y7\nViaTwmmnzwcAPLNZlm3mstMTY5IkoY3IG/btmhW3g34lYhednGMhRa3TP7I2bv/+dTvj9rGyEj2L\nFP13zajo4zJIgudd8c2xqDx3vnS7fP6jTpQbSZ4t+t57g8ssmyhQWWjlRttzyInYV1+jMhnT/xS3\nzzvHfe99Ny4S48zQM3H74G3vE33V4Z1xm0VHXTU8IcqGy74wdNmAvQuXumPLYaKqszHyflpa1yxp\nNP/4+Q4xrjDhRP/CqHx2qsS5P3HMjbOqdkOFymZ/f/ydou+7X9ket8OqFNMjItzIBe45ndUjK8cX\nxlwUYlJpGcylx3UM8kvOEuOS5F4uVFSZr6CmxkxX9k2Mn9Go4xM0ZimACwA8AmBu/UcBAA4AmNvg\nax4eHi8yzHjjG2PaAdwN4A+stYLe1tYsVlMmAhtjrjPGrDXGrJ0oDU01xMPDo8mY0cY3tayZuwHc\nbq39Zv3PB40x8+v98wEMTvVda+2t1to11to1+Yy3/3l4vBhgpqsLBgCmpjTcBuCotfYP6O+fAnDE\nWnuLMeZGAL3W2vdPd6zT+8+1f/n73wEA/MuXtok+Dt0MlXspRRlWfW1uvh9e/ktiXJl46pWnDFUK\n/1z6IVdK+G3vkIwt7FLSmXXZvJvHa3/Bzfc33yiJQ7d94dfdhyF5fHbhBWlJA5NIuM9L//D2uP3X\nX5Hj1j3hdPdiUa6VuG665oQSyL58x4K4ffjmC0UfIreOKQpTLhSkPaGty80rUvp5MulcZ/s6Vsft\nv3nik2JcqUhuNGUAYDedJVYmk1AhxlTmO1SuMnYJctsoolO2L0QV1cfuWuX+ZRsFZ3N+8lPSfGa+\n/HNxO5NVGZtkSEl2LXTzTUlbxnifu0+nXXuL6BscrtkQrvrVN+HpjU+fUNGfiR//FQB+HcA6Y8yT\n9b99EMAtAL5mjLkWwC4AV8/gWB4eHi8CzMSq/z9AwxKcr3lhp+Ph4dEMnFDUfyFx7srz7He+eC8A\n4F3velr0lauNiQpzRDJoq84N89k1vyrGFUbI/abcLhxhlaD26b/zV2Lc4Ye+HrcPbXlM9CW0LHr8\nVEo1YZdKpHjehSiuuegpb5CPESSlaMhny515qehb9MsfjNtb9ruy22ctka7JnX/6WncuK0t5Mbkp\nE3HoaMhEsnFpKc60CzpdNOT4uCrDlXfuWXaXAkCQ5joG7n6WynK9CyXniguSUjy2pCaGGaeSBR2z\nxLgclQrPdUtbVK6HSo8r9S8/y6lMvD4dWenG3f7Z34/bUShdiZw5OfcDD8Xt3/xt6ZqsEMlIpEuR\n1c/90K7fwVBxywlFfR+r7+HRgvAb38OjBdFczr2giq7uWghAMpAqhp2GrqxEkWuZjOtd0C+j0XZt\n3Ry3qxXFl9eAi2zL/3uv+BwRZ3023y76BJ898aEllEVbVMjVlVfJ6mysnFOFyDGCQK/C1McINj0k\n+rbc/EDc5gShraFc76QVIXOir1BwYmqaOOB1HYMK8/GpZKSOG74Vt697tyOX0CXFWF3Qaid/5noE\nZVWTocA1AxLKyxG4zyHVWqiqyLcg2fgdWI3YOyLBc+Rj5AJJ9PHh1RTpqfkJKUqzuuOHcfu2j0m1\nJSSvDzrniL5kzzIAwCveqmo1NIB/43t4tCD8xvfwaEH4je/h0YJoqo6fSABt7bXfmjNWS/1l4xMu\njl+TRrBGZEg/ysyaL8aF69fHba6VBwAm685386avxe2hUZXllCCXmtIXq6KkM2XxQeqt7N1LpeRv\na0T6aSot9TGOrguJ9CKnfp4N68JV6fKZ1ev0wO7Z7vjdvdJecf0fOtfW4J9fJvpCil5kNx3X1AMA\nK+oYyDmmqSz0H93cHbeHjkn9vFhwunuhLI9/9JBz7w0POXfk3p3yWnZuIg5/pf+X2AVL9fGssr0k\n6doS0GQbdDxlG2AS1wStW+dcVUuQSmNrDpAS2Xa2/POH4/aGM6X95uv3OIKQdEq6gscLWwEA2/dK\nl2gj+De+h0cLwm98D48WRFNFfaAKhDURKEhL2bCdEj5GhmV5rYBdOewOO1NytCf/x7mydCRZsuRE\nxbGSO761ireP5XTFLsHliUKKn0sFquwxkTxUNQcalbiyyo0WWk4ioRLXKjKQJdFUsld0HTvoXI6G\n8iWDpFQJ3vVuFxVXUpOsknicoLUvRSoK0fB7Q67VwJ9eHLcXULnuheqaOUJRVeFGijgVy+Sx+7dz\n14lxG59wFzrZ3UbXQvP96m0Lxbhdt7wybieVesZ1Hqr6maD5c0kxXcdAHE+pEpbUjF1XPOzm+Ncy\nwatKvIATBRmJmdIl108A/8b38GhB+I3v4dGC8Bvfw6MF0VxefURIoUay+bEPyeyoY6NEphDJ7CjW\ncIvsrkkvE+M4zHWiIDOgWBf79AW/EbejhAo1neNchEfGpC52+qrz4/YY6d1Rmwyf7OiZ5+ZOGWYA\nkGxzbq5E12w1f6qbRuW0Q6t0QgoRrkRKH6WxFSJn1IQd2bRbR20PYeKJYoVIIpQfqgp2b8q+FOm4\nIdWGS6iy5EIXVpmMFQplTdDabF8viVrzOXLBQq8HEYJW3TPWl5I2jyNtbv4lRcSZpmekpLI+KxQK\nzfUao2rj8GO9BmyHOP2+/xO3v/RP0p133budLSNVVSW0o9oa26kZ8CbBv/E9PFoQfuN7eLQgmkvE\nMa/D3vNrFwAAhrdJkgtDAn0yoTPTXB+TNWRzKvKNoum0+CpIJKqNxdeIXFlBIH8XOaItoAw87bph\nl6POWuOxxYKMMmNXUUD86hWVWZfKONdnWZeuJpGbryxUEW2WvheoSDJONmTpW1X1Fm+NREoeJJNx\nrriIIjEDFf3H506piUQNxFbOjASAcsVFxenHmes1hMSlZ1T2Y4mILVRwHrLkKiuW5HMVskhPz5id\n5p2qMy/5mWZVRY9jZS2dkTyMaKtFM7793wex4XDZE3F4eHhMht/4Hh4tiKZa9ct9/dj9zk8DACol\nLeZShVlVaClFpBEVirobnJARfmkS9XNQ8tqIqzhrJ1w7KEoLsRl05ZLskT2ib/yAs6p2EIFER1qe\nq0yW32ReUm9XJiiJIq2i2FjMIxUhVOJ8RNeZzEhVolwmrjdSWziqDID4yQ/UMbiaKwclVhWZiaj8\nq6zYJapam8k5i3zVqohKtoRbed/F8TnCT18LicTVUIvipEKSrhKqyrysuhmlclQpoSep7llAKWSW\ntlNFXUtAngFdEi3IOrHd0joWFAdhlsZNFOWzn6qXCrOKXrwR/Bvfw6MF4Te+h0cLwm98D48WRFN1\n/CMHD+GOz30BADAyJrOLznjZBXH74jdcKfrCrIt+SxIBgXJoiPJUJeXXYRdQNcEuL8WJ30CvBICA\n+orkappQepUh/W5E6cWcgVfVmWoUdZdMS72bwbpvpHxPEdkXmByzUpH6YpXtCYnGj4Fwg+r1oD6j\nXLCGiCdTlBWX1uQjfAx9/GDqOgNQkYx8jKq6FyVK6+O10fW6eE012QbPI1FtTDjK7lijIvzYLmGV\nHSJBn9kGYlW5+PEE2cUiaSMzEzUim3DjxzATnPCNb4zJGmMeNcY8ZYzZYIz5SP3vy4wxjxhjthlj\n7jLGPLe8QA8Pj1OGmYj6JQCXW2vPA3A+gNcbYy4G8AkAn7XWLgcwBODakzdNDw+PFxIzqZ1nARwn\nEEvV/1kAlwN4R/3vtwG4GcAXpztWkEqic24tMeW8V71K9N3xWVfK6u6/+bycJIn3wSxXzujjt/+r\nPD6VpEqqslMiQpFcJpPKU1WZuEG5dapOvPrxV10122/+wz+KcflOx+9XGJNul0bRaACQSTnX35/d\n8824ncpIoo8qcbT92S/9sugbP3rEjZsmfovXI5POib5szs3/xju+4jpU1J3g/lM8iR9/22/F7ZDc\nUtVJzCRrjbfbAAAgAElEQVQOvG4A8NGv3xG30zmn7umIyjK5hstKhfzL634vbifp3Pv27xDjkqQK\nhuq+f+o733Z9SqVJUFVgLhWhI2INPVdaHeEoU37mqvluMS4UpRDkHMv19a+mZFJYI8zIuGeMCeqV\ncgcB3AdgO4Bha2PFZS+AhY2+7+Hh8eLCjDa+tTay1p4PoB/ARQDOnOkJjDHXGWPWGmPWFiYmTvwF\nDw+Pk47n5M6z1g4DeAjAJQC6jSOG6wewr8F3brXWrrHWrsnlZyaGeHh4nFycMDvPGDMbQMVaO2yM\nyQG4FzXD3jUA7rbW3mmM+TsAT1tr/3a6Y52xepX9m2/WylDrDCtDNc4+c807Rd+e3S50lt1Bf/nv\n/ynG5fJOR9QhqoIWkkkibWMXkl6bkIgcbn7Tm+L22MiIGNdDZZY/+JUvyTkSv/r1b/81OUdak+Wv\ndDaQd3/4g2LcTVdeFbdHR4ZEX5LsHH/1/fvjdqRCVFmvvO3Gm0TfxkcfcXOi4334ztvFuCyFI//Z\nL/yK6LPkPkzknQ3h09+6W4wb3rwtbn/sg3IenMn4J7f+XdzuXNgvxr3vDe5eJFU9BXZVfuT2f4rb\n6YwMpS4fdZz1f/z2q0VfhWru9fRKApmbv+5sMcKtqAhSE190W2O4cFT0UZVv9P/fa+L2hj+/WYxb\n+Jefjtv733e96KvW5/jRtZuxc2T8hNl5M/HjzwdwmzEmQG3/fM1a+11jzEYAdxpj/gLAEwC+NN1B\nPDw8XjyYiVX/aQAXTPH3Hajp+x4eHi8xNDVyb9/WrbjpqpqYqiO4qlzCWJFoZNudWPaHX3AiXzYn\nSylx+as//+3fFH0RudXKRSeGRoF05/3V3U50m8QjRxFdY2OuRFJPr+TOO3TIiY3vu/odog9R4xJH\nhtxlhwcO0t+lKWbxOSvj9obH1so5Zt31fPGmP4nb17z3D+Uct7iS4hvWSlKUqij9TCXLeqS7LSq5\n9XjF6y4TfQ9859/d/MfdWr3n9W8U4yxFTiZUlONFFzlu/o5FC9x5lTssDF10HhNqAMC8RU4tMHkX\n61lVBCym19Un6O6TDqpSyalTbe3STpXJ0fNDHIeaCGbP+ifidt8nPyL6urNOfSh925UXN2+Sa5Wn\nOgNnXPce0bf7C58EACRmSKzjY/U9PFoQfuN7eLQgmsq519vTbX/uNbVSRVueeFr08Tw6Fy0RfR+5\n7ba4nWB+OyUCU47OZF6zkEpLJaZOIAEAywk8ilzib//ghrh9aK8Txa0iXfjwv/5z3M60KRcmkTrs\n/+EjousTH/2LuM1W4U986y4xLklJS8wzCADhMUcs8tC/OCv8PXd+TYxjTriqegY+8uW/j9vdpy+n\ncfI6P3jlm+N2YVxGKHKJ45vv+irNV/EpUlLKh39JWtMjImfJEpnHZ+6/X4yzlBDzvp9/i+gzZXcM\nFr+ZQhwAUkSUodXQi6/8ubj9pt99l+jLZty8pttLCeI8XH/9u0Xfys87i/+hD98Yt7tuep8Ylyu5\nORdyMkXN1KMSf/sXr8bm9Rs8556Hh8dk+I3v4dGC8Bvfw6MF0VQdvy2fs2cvXwpAZjUBwF/ceWfc\nTmWlXizJIJyemUtJPYc57IuKqJAJEwIqYRRonXMaYggmchje6iLOPvHHHxLjQiJ/KJDbDwAsZbHp\npTc0/1u+6dYj3y1LivF6JBSRyId++e1x+9hhl6mXVLaMJeevjtvv+cwn5Tyg6xocn6+c8PCGTXH7\n438k9dEKZRBWiPQipfTniHRfze/P57v0LT8ft99y/e+KcUlRM0Gux79+0kW7Pf7Qw24eqt5Be3dX\n3P6Lu+4QfbweEVRJcXp3Zol8xCqiD5CNaed10sXLhCZsy+j86GfkMfKu/Jqt6nd27bn6rSuvxOan\nnvY6voeHx2T4je/h0YJoqqjf09luX72mVnG2UpSiuE1xZVdZrZSJOObMcZVoA1W6qr3dRfKNlWQK\ncFtHX9yeO99FZlnlEgyI9CLbIRM5OjucOJhMkTis+PFYXGvvkNFuzDHf1iEjDyMSx5lXX/OwJzna\nUMnHLNGHRDxhJnHiu+8FqWn4/ZiYREU5sruzCjnHKrnRAhLnS0oFY+KJsrqfXHGW3bi5nCQOESrZ\niCTiEHOia0mptQcdXxOTsGqlI/KqLPpzRVy13sw/YpW6YKjYGd8XTQTDnIfKswrU3brXvO512PTk\nU17U9/DwmAy/8T08WhB+43t4tCCamp1XCYGBoboepNwRxYIjqAgVB/xZKymEN3Q6OBNvAMD4MRc2\n2tUpM+aWzadjkC6WTWr91unu6aJUpPIB2R5IV+3qle42M+502n5Vzrib7AHt6jqFrkqln5NaXyw7\nF+GkUsrMy44TqnoAgIQep12cx8+lXhOcWafDmyNSaiNRq0D7MN0xwpLMrKtacq1WyCah6h2yay5Q\nobhcO69CIcAYkjagBN2XhHJnsoewWCqIPq5ryPXseO4AMEG0c3v2yJqMBw+7bM5nn302bu+nDE0A\nCKj2X0mTltZrEA7u3oWZwL/xPTxaEH7je3i0IJoq6idy7eg4q0auUC5IMTdNYm6lLPsOMJ8785od\nk6JhMiD32zH5m/bU0wfidkTicFq5spiPr1yWZYo4+09woStRnD8ZJYpnqSR1VJYuMBZZmXs9VNFo\nLM63qSjHsVHH/1css+gphiHDLkhV7omj6TrbnQtz/8H9YlylVJzyOwAwTtl6SRa/IzkRVh+0a9lS\nqfMEraoKQhTlu0WZcAD5jFsfvreTynXRzZ1UhZuiTEMr75mhzwGXJVP+NuYP1GJ6MjmzbSj4IFUd\ng+PuzqJSlxrBv/E9PFoQfuN7eLQgmirqV6MqJsbq4qESX1n0qiorc5WjmaitRWCOiNJBTwnyIpQq\nblyxKEUjjrqzyjLLiT4piibMpKXlni2/hYKMQpwoUlKKUgMMiWliPTRVM02rNCZF24hvadqJ6Vql\nCeladOJJ0OZOMEoW/rY5y+QxSB1JZ+Sj1MdRcsSFqCPfKiT26kQiIY5zCSqr5kvrOF6SKkeO1ERO\nENLqWUBEHKwi6bH6XnAyToqs7lDivKhwrNaAvTb8jGV06TTSQYyOuK3rcsH2LZgJ/Bvfw6MF4Te+\nh0cLwm98D48WRFN1fFutxpl3CZ1VJtx5Sg9MOt0mleApy2OwzqnTl5KB07/YbTaJbIPdaEoXY12v\nRO4rTfrBx9SZWO0djkzBqDrWo6MuIo3JIFMqKy7iaLRQuZf43NPoldNlnBl6H1jSp7V+K+wQZeWK\no48hlUerVOQxckRGWi42Lqoq11S+r0JyEWZUJCZXDqtW2AakS1U7W4nW/6HWh8Fkp4VCoeG4RvcF\nkEQlnIVYKip3Ms2roNynxwlfI+23bYAZv/HrpbKfMMZ8t/55mTHmEWPMNmPMXcaY9ImO4eHh8eLA\ncxH1bwCwiT5/AsBnrbXLAQwBuPaFnJiHh8fJw4xEfWNMP4A3AvgYgPeamtxyOYDj5GG3AbgZwBen\nP5KFrdZE05LiJBNRTwnp5rKUCBEy4YMSyfJExBFWlLoQUvVWds9UdASUE1x0KS8mpWAR3iqRnUXi\nTlVyaWRomI6hxF5y3xRL7joTKo+oTOK9VW6jKom9LFJqrvggIFeRUnfKJYr4Y045VYmWSTW0a5LP\nbcKg4bgCEWeESj1jsT2iCDnNQcGuPi1Gc+Rkmu5tSd13Ow2JhiBCsY3FfnFetaZcTyClsp1KVD6O\noyGDlLxnSaqmrDkDo2q5ft4ZTW/Gb/y/BvB+uDXvAzBsbexY3Atg4VRf9PDwePHhhBvfGHMVgEFr\n7U9+mhMYY64zxqw1xqzV6bYeHh6nBjMR9V8B4E3GmCsBZAF0AvgcgG5jTLL+1u8HsG+qL1trbwVw\nKwC0dfY1j+DPw8OjIZ4T2aYx5jIA77PWXmWM+TqAu621dxpj/g7A09bav53u+6lU1nb31MoWR5PO\nyyG7EgEpLgGNK6sMpbmzHPnG0eER0cfcCsItpVxUgVaoCaz7sd43KTuPzqV1sQTcdWs9M0g6vTtI\nkAtMuQvLxFmfTKpzkx7Ia5zS4cG0pqOq7h3bAxL0PaMy63gdAzUPXtUwZDeayorjeWlC0JAJPBq7\nw7gvVC5evjfC5qEIUkLKlOQ1BKS7s7NHlWZPu3vG9qGssqnkKIuypMlTKfw7m3PfGx+VNRm4XHpS\nEY4ct7dsffJBTIwOnVSyzQ+gZujbhprO/6XncSwPD48m4jkF8FhrHwbwcL29A8BFL/yUPDw8Tjaa\nm51nbSzmaPGYxbAgaDwtFu+TCSnRZLJEmFBVPO8kprLqoOcRVRu7jaoUBsai86RjELebdhf29nbH\n7cLEsOhj0blI4mV7XvK8sxst1JFwOTevKomUms+ekVZEEIJIRGTFyXOFrGop8ZjvZ7KBuA0AEakt\nWg0QxxPtxtl5KXWMsExRcRytqIhg2FWrHXasuk0My+i8CpVLq/IsVQQdZ9pFkY5yZBWExoXy2eFo\nUe2ePb4mlWmiHxk+Vt/DowXhN76HRwuiqaJ+PpfBhatWAgAGDx0QfWwVDqaxzHZ3O1F5YlyKa8uX\nOaKIvm5VSVeURWKCB2kdTWQoykyJryFRXnNiSLpNiuKFMaqWq8qBteWddbdvzhzRNzbmrOuirJVS\nF2bNcd6Lsoou7KYkIJaqteW+QJ91ddwk8QKWiJRCOVGQIKKSoipZxt6MiCIbAyWKs3dE89nx/Dna\nLVRiNJdSs0o8TiVZhKeSX0ptqU7jVUqIKFCZHCOcQqQTaBrxMqkcKtBTeHo0zyODufl0wpTzRs2U\nUt3Dw6Pl4De+h0cLwm98D48WRFN1fFgLRDW9PJeSp2aXjHbrlEhPDkkH2r5tsxh31Rt/Lm4vGpsv\n+vbu3R2377777ridTEq3SJWj3VTU3ZzZc+P2CPHX/+JbfkGMWzewIW4/s/kZ0bdo4YK43dMto8DS\nodOn0wk3rz37d4tx7W2udNicObNEXzRxJG5PjLvMt7astHnM6nN2CU0gsWXrhin7Ojs7xbje3t64\nfXRYlnti9xUTjvQqu8b+I46rX2fu5Yn4dPiIc32mFAllW5uz+0QqW7FMhBshEbwklD2hNOHWqm+2\nLL92+KC7toULF4u+o0OH43al4I4/Z+5cMW58zNlAemfLezY06q5NZDwq28usHlfqvRpIG0JporYv\njiW8ju/h4dEAfuN7eLQgmirqFwoFrF/3FACgu0dWmD16xImoWsSe3edEnGe3OjfgpRdfIsZdetHL\n47YWGzMkNvb1OXHz61+/U4zr7++P2+w2A4DvP/SDuH3LLR+P2//ylX8W49raXSmvcuGo6ItCJy4n\nIMXvBXPdvFjku+H694hx9957b9weV246vm52+WzcuFGMY7H9vPPOE33J7e4Yc2fPc3OPVDQkJdEs\nXiDpGPYNOBHekDt2cFCV4SIX6cSEPH42SwlHkVuPLOTz0dHpRP+9e/eKPo5wO2fFirj9+OMyy7xK\nTrwVp50m+ub0uucvVO7CI0cpMpAeuZ7eLjFu+Jh7Dg6pNVhx+vK4/czW7XF78ZIFYtzAwEDc1s93\nb19N3RkY9KK+h4dHA/iN7+HRgvAb38OjBfGciDieL3KZrF1a16EHDx4SfW1tTi8eHx1t2Ldo6dK4\nfeyo1J8PktvlwgvWyHOT3r1t27a4ra9/3jyn0xZVuO3qs8+J208//XTcPuecs8S4LVudC09rXL3k\nksmmpVuqd5Zz82zY7AiNNVf8z/zMz8TtL3zhC6LvAx/4gJvHtq1x+9lnnxXjNm1yLrvly89o2Lek\nfwkage9LUtXOGz3magTwCu9U8winIa9sI7ddrsO5MJm4EpD3Sd8zthe1ExnryJgkaskTUcaoev44\nZHwe2TwAIEtu0mTKjduydasYF1BdPV3HICAXXJLcuFqPz9G5QlUjsFi3gRwePopypXJSiTg8PDxe\novAb38OjBdFUd146k8ZpdVF91Zlni749u3fF7Txl2QFAsUg88kQ80d7ZLcZ19zpR+UeP/Ej0scjH\n0WivfvWrxbiVp5/uzluSrhtWJeYucJGB5ZIUL5krbv5C6eZiEbikSmh3dDkX0JOPr43bS5dKcfuJ\np5+K22956y+Kvgfuf9DNi1iN9+zfI8axSDxXRZlt3Uqllo1b74sukoRLd911V9x+5StfKfr4OrlE\n9yWXSBfswcODcXv7th2i74ILnbrGkXB798hrOUSu4KQiFWGSkZExx2GnNVye1/333y/6lixx679j\np1RVyvRsduSd6nP2Svl8b9zi3KlavVxI93fwoFuP05auEOMShsqZyeljz67a/jE+O8/Dw6MR/Mb3\n8GhBNDlJBzieG1FRJTYHDrlkhxFlES2RBXPVahdltnefpPKf0+dE/avecJXoO3jYeRE4mmvRgkVi\n3O13OPH1rW99q+grEj8cR8INHJDzuPCCl8XtBx98UPRd+YY3xO0jR2Rii6HIOLboLlksI8lmUYSf\ntvz2UETkbhLv586S4vyqVefGbW1lHiORuI+iJp988kkxLqTIwNlzZVLUAw99P25fcIG7Z//zI6mC\nIcEkHfI9tJui8DY/4zwlR0i0B6S1XlORc0IPk34IfjwA//lf/xm3I1XebSs9j5ooYzYl9PBabd0h\nn+Fzzlkdtzdtlsllhw8579Q5ZzkP0dPr14tx73jHr8Xtr915l+jL1qsOT8dbyPBvfA+PFoTf+B4e\nLQi/8T08WhBNjdxrz7fZVStrOsxGikwDgJedd777oHjqWbc8+2ynK3URIQUAjBCZQle77Pvhj/47\nbr/z138jbn/z29+SxxiRXPeMRMKZRFiXvuCCC8S4DRtc5FtnmyTb2LXbuYP02r/6itfG7e/9h9M5\njSKGfOUrXxW3B/ZLO8Gq85zu3tnh3IM//p8finEHDrvvzZsnyTF273bEHxzFdv7554txfJ25XJvo\nW7jQ6fwbKRIwo4hP3vDGN8btYRWJeXjQubbmLXaZau15SQjCuvXtX71D9MlyaW69V66QrrKduyXZ\nCYMz8l6h3JF7yLUYUBnxOX0ys/PZXbum/A4gXc0mcDq6UTYP5u8855xzRN/Guj1guDiOMIpOqOjP\nyLhnjNkJYBS1WgOhtXaNMaYXwF0AlgLYCeBqa+3QTI7n4eFxavFcRP1XW2vPt9Yej6q4EcAD1toV\nAB6of/bw8HgJYEaifv2Nv8Zae5j+tgXAZdbaAWPMfAAPW2tXTnechEnYbD3hZOUKmRjCEVebNkk1\nIE8JNhMTjrtsxenyGCzy6SgwjmJbtdqJSU88Ll1UzBXHHP4AsIvEteXLHXlCKiFdapwco8krLrzw\nwritXU8byc2zYoVbypxK5mEOe75mALj6l98Wt2+66aa4vXCxjCDcuNm5I5MJKfidtdKde+t2Rwyh\nS4Uto4i2w4cPi74uikJk9+lW5apllUk/i6zgDB1zKpiirBcuLO2mS1E5tmLRueJ0tGL/AiYcke7N\njVvc8zhPcwbuc+QYnR3ueTlrlRTFjx5169Oek+rfuo3r4jarFYsXS36/A4NOPcso3sHjhCxjxYkZ\nifozfeNbAPcaY35ijLmu/re51trjV30AwNypv+rh4fFiw0wDeC611u4zxswBcJ8xRkQgWGut0aVD\n6qj/UFwHzLTGh4eHx8nGjN741tp99f8HAfwbauWxD9ZFfNT/H2zw3VuttWtqtgG/9T08Xgw4oY5v\njGkDkLDWjtbb9wH4cwCvAXDEWnuLMeZGAL3W2vdPd6wgkbD5dI1MYMmipaKvjzLrjo0eE33sAmM3\nRnFC8cFvcVllOnRxFpFcLKSMuZGRMTEunSI+ePWzyMdnHV+fi4kzNDHE6Ji7tvnzZZjr4EGnB159\n9dVx+7777pPjyM3V1indlowEacmai55DjrU7cutWR1QShk7f1cSenZ1OV730kktF3w/++2E3juoF\ndhIXPwA8u8u5trQto1R1OnmF9G6jntlFi13Y9b7dkmyT781yItFkew0ALKJnQl9nOxGTlhXZ5t59\nbv6dXU7H12QevM/mqPDpPrIlbdvubCCcrQkAcyksep8KVy/U7T5HR4ZRCcMXxJ03F8C/1RcwCeAO\na+33jDGPAfiaMeZaALsAXD3NMTw8PF5EOOHGt9buAHDeFH8/gtpb38PD4yWGpkbusTtPkzqMDDvR\nSIthzAG/gNwuhYJ0hx2lyK9jx6S6wJ4odpkklCtr5Rlnxu2sKjtVLDnVoqvNzWmiIEVDFu+1u+1/\nf/zjuD1ngRT1T1N87vF3/vd/xeeXv9zVD/jhD2VEHrsL26h89w9+8AMxbtosLsqYy2XcGqxQ0W4i\nck+pEkxs8SPKyGNSCwAYOuruk0lKt+jAQcc/z+5e7W7rn+ei+sqhdJ8yeQrfz2VqHuyq1C5HRlmR\ns5y+3JHG7Dvoaj7ofXXOWY6YQ3Pzc8Yfl3TTmZcchciZhjx2/ZYNGJsY95x7Hh4ek+E3vodHC8Jv\nfA+PFkTTdfxMPYRymSLUzGacy0frn6wD2arTj5gDHwAOHXLMLMz5Dki9ajuFoV52mSSJZF34dCLe\nBICA7AFtxPO+jjj2AaCD+qpVqc+xrvrsTmnLOG2pW5MEjRvYL2ut8XrosGJLIatHh9x6VFX5aF7j\nTDYn+ljfrZSpZp2yeZTLTs+cq/jmOYSXY7u0Ky4k8tSly2SIKq/VWeTGnaPCZteufTxud3bI+/4j\nsqlwOO/SxVLHb1RzEAByVHfxQpWh+I1vfCNuL6C6i1o/3/Gsu9eR0vHPWO5sO4fJTtXdLV2fR6iP\n6zMAQDVRu79bt2/DRGHC6/geHh6T4Te+h0cLorlkm3Ai5q6dkoygnUTzPEV6AcAllzj3Fbu2dHQU\nlxFuz8ljsHjIasD3v/99MY5VkB5VyntsxJVdSqecKKfnwdlooXI9dbS7vtdcLsMgHn3ssbi9arVz\n/+zcJTMNM0Tc8DMvl6XCvvef34vbLPanAuluY5fY5a+6XPRxdOGBAeei0lGIO/c68fVlL3uZ6Hvo\noQfiNq+HdrOeReXHtIuqRCrN/5JL8OAhWX5t6VInKnMWHADhmuRskv0HBsQwPvf4uIzm7OlyIveG\nTbLcOKtMfAy9VhZuvVkVBGQJd37mjo3I56oaOhXkwD4Zobhs2VIAQMKTbXp4eDSC3/geHi2Ipor6\nxjju9KoqArScLJsbFBHHt77lePHYWqo9EquJYEMTFbClukCW6lJJJvow0cfax38i+s471yWzbNvu\nEodWn3uuGFcoukg+rswLAOescqLthg3rRN9ZK11k3LqnnKdA8833L3JJKfffJ3n7lyxeiqmwatUq\n8Xl42BFbPPigLBm1gJKHrHWiY7kgOeWXU4knjuIDgCKt8UJVRoyxkM41oe7FwH6nZvD9C5Q429Pj\nkllY3dNg9aZNeTJOX7I0bm9XFX0XLnLz37FDql1M9LGX6gBoz5QJ3PyPDkmGujlzXALZHhLhWUUC\ngLExJ/oHgaygfKxeCyGq6uJaU8O/8T08WhB+43t4tCD8xvfwaEE0NXIvlUza3npp635Vs+4ZyojK\n5qRuUyk73Swkl4kmsmS9XpdLtvQbx1F85yn9fN0Gp1vrOmmL+5dM2ad1sb1Us85ARnBxfWZrpauP\nS7ZdccUVcXubyhbbv9+RMPT0yMg9Y9z5BogkIqtcpPPnO711v4oMZF2Yn4/ly2T2YD9FquU7JIHk\nf1EtOtbPddTdIXLNcflyQLq9Vp3t3Jtaz+6j+nXPbJNrxQQkfF2Bui+XXOyyRXX23ObNrm6fjjjt\n7nZZmpyFqEk/Q4py1McYGHAZhIsXujXdPSBd3lXi10il5fO9qG73Wbd5PcbGx3zknoeHx2T4je/h\n0YJorjsPBsk6B/2uPTtFXy7vRLJ2VXZqgKKsVp7h3GGbVblhFrnZnQRIQoyjR507ZUzxq6UCd4x5\nixaIvkrZRWNxeaOq0pZYPLaQYiOXodIiNkd7Pbb2ETqgcuf1OzH9WeV64nMvXro0bh84cECMSybd\nMdesuVD0Pb3euRlZNC+HUvWZqDjR/OHvyQhITnSZ0+NEcZ28sohck5q3f/uzJNITScf+g/JalpDo\nvHC+vGesLmzb4ZKzZs+SCTDs3uTISABob3euv3XrZR2GgN6dl13uIiDvvV/yJJ5F5a+Hh0dEH6us\nO3btjNtXXy3LtH/r29+J22k1x9F66bcoks9bI/g3vodHC8JvfA+PFoTf+B4eLYimE3Gk62SbmkAi\nSfqd5pvnUMg8hVp2Kd5xLr2tdUlLIZQJ40wbfSoDr0gupXJZZljxvHYSH/xZZ8uSgWx70KGbtkqf\njQyv5HvR0e6u7WxyZQFAPufsIY8++qjoYzcjk2PqrLLZfVzHQOqcCSp80t3r1mdMZYstXurcm888\n84zoW7rEkWqcvdLpt+vq5ZyPw5CtYe+AtHlUK879tmTRYvq7XLe9A+75WH6GJARl1x9nZRYVaSa7\nghPKzTq319koJirSzsF1EyPKwBsbkxl+/KzqOoNM/Llvr7NnBRnpJuZ7m01LUpRZs2v3ad3mjZ5s\n08PDY2r4je/h0YJoMhGHha1HT2kedhZLH3nkEdG3epWr58GkF5m8dPv1L3JunWJBiqUctTVybIza\nkhiC3VCJpOL+I872gPp2794txrFIydl+gFRBZiueOh6bz7ljrFv/lBjXQ2qSzrrjLDkdPcZIEpHI\nmjWSzOMnP3FZiVyroK9HusCYf15nQy5d4u7FfQ84Uo5eVUKrQhl/c0j9AIDBQRfVx8/LaFne2zPP\ncOXSj5JbDpD3k112c2fLCMIly5bG7dK4vGeVIt13Vf+RK6QPD3P2nFQ12VW5+lx5z44ece7lTlKt\nhtSzWSo7NXT+HLlWY/VnOopewOw8Y0y3MeYbxpjNxphNxphLjDG9xpj7jDFb6//3nPhIHh4eLwbM\nVNT/HIDvWWvPRK2c1iYANwJ4wFq7AsAD9c8eHh4vAcykWm4XgCcBnGZpsDFmC4DLrLUD9TLZD1tr\nV/7rox8AAAggSURBVDY6DlCrlpurV6PVFMYcYTU6Ki2iSaK1Dij5plyRVvcFC1zUVkpFNrGoxZb2\nAwOyurcu8cTYQqItW9r3qijEIRKPrZHaFM+jS3Gvcd+8ua6i6p49koabiS10+S6mAB8ecaJiMiFF\nTy5LpsHrwx6VyMp7xiQUVWUJX7V6ddwuFNx92qKiLdvFfZ+Gu5ASZ7TKwc+wViX4On/yhKPhnqWS\nhSolF+mpqdl5XrMpIQiQ0ZecfLNbUafPpsjRfLtUUVkFiSJ3LeMFuQ+4yq5WIY/TuO89OIBiufSC\nWPWXATgE4J+MMU8YY/6xXi57rrX2uO/hAGpVdT08PF4CmMnGTwK4EMAXrbUXABiHEuvrksCUooMx\n5jpjzFpjzNpmxgx4eHg0xkw2/l4Ae621x03t30Dth+BgXcRH/f/Bqb5srb3VWrvGWrtm2gqtHh4e\nTcOMIveMMf8N4LettVuMMTcDOK4EHbHW3mKMuRFAr7X2/dMdJxkkbXdbLYIpmZG6L5cOWjS3X/Qd\nOuKysRYvdhFcmpBhVq/TNoaPSULDrl4XOTVKbhfNca553xkcuccc6laVyQooqkrrhAdIJ9QRXOwi\nXL58edzev3efGMelq+bNl7pqgbINc3mn32rSDyal1Hox/0Cz3eHA4EExjp+d175W1gjYscNlDXLZ\n80nPm05tJHAGXZL0fV0mm0tLhcoOgYiJT1yb7UGAjFZcvESSxOze5dy1K1acIfrWrl0btyuUGafJ\nWRbMc8+OJgRlm0JI8+3skraAkSPu2eydrV2ftffugaODKFfKJ3zDztSP/3sAbjfGpAHsAPCbqEkL\nXzPGXAtgF4CrZ3gsDw+PU4wZbXxr7ZMA1kzR9Zop/ubh4fEiR1OTdNKptD1OyqATbEbGXaIIR4sB\nwIK5TixjMWlBvxTJ2IU3rhJP2GWSJr6yZFKKZBNEhqHLIOVIfKuQe2meSiqaOObOHWTlbyvPUV8n\ni9WiQrC6R0wqUtGEI71OBDxCfHZaPOYKsHPnSIfMbiqNBZrTElVhdjMl5ug5RvSZE6GOHDkixglV\nSInpgoOP3L9Vq6LnqDaWdtPtI9Wqs9M9c1ql40i77k75bIZUaVjz8XXmnZjOPI9HR+TxeX105eIs\nRSVWyqQuZGU0ZBuVhRtRrs9X/OzPAgDuffgBHB0a8kk6Hh4ek+E3vodHC8JvfA+PFkRTs/PCMMTR\noZoLS4ccMjFHe066MZgokkN9q6Hk1R8mvb6zQ4ZdhpwxR+6wDhWe2dvj9OehYamDp4hgs0L6aJ9y\nh5XINnBsWOp6Z555ZtzW7jy+NtYztX5+3HUDAEbFTRXG3LqGnGkYqExDIngcHpP6Iuu77WQL0GQe\niZR7fGZ3yjVgrvtjI2RfSclH7sgRtwZLFkkbwvCQWzvm8Gf7BADs3Lkzbo8r8lQuG816vVX2hEX9\nzk3M7kcAWLjAnVuTlrDbjtsdquT3kuVL4/YGRUbSTzUO9h0ml2mk7m3JPVdVNf/19TqMujZBI/g3\nvodHC8JvfA+PFkRT3XnGmEOoBfvMAnD4BMNPNl4McwD8PDT8PCSe6zyWWGtnn2hQUzd+fNJaws5U\nAUEtNQc/Dz+PUzUPL+p7eLQg/Mb38GhBnKqNf+spOi/jxTAHwM9Dw89D4qTM45To+B4eHqcWXtT3\n8GhBNHXjG2Neb4zZYozZVifvaNZ5v2yMGTTGrKe/NZ0e3BizyBjzkDFmozFmgzHmhlMxF2NM1hjz\nqDHmqfo8PlL/+zJjzCP1+3NXnX/hpMMYE9T5HL97quZhjNlpjFlnjHnSGLO2/rdT8Yw0hcq+aRvf\nGBMA+AKANwA4G8DbjTFnT/+tFwxfAfB69bdTQQ8eAvgja+3ZAC4GcH19DZo9lxKAy6215wE4H8Dr\njTEXA/gEgM9aa5cDGAJw7Umex3HcgBpl+3Gcqnm82lp7PrnPTsUz0hwqe2ttU/4BuATAf9HnmwDc\n1MTzLwWwnj5vATC/3p4PYEuz5kJz+DaAK07lXADkATwO4OWoBYokp7pfJ/H8/fWH+XIA3wVgTtE8\ndgKYpf7W1PsCoAvAs6jb3k7mPJop6i8EsIc+763/7VThlNKDG2OWArgAwCOnYi518fpJ1EhS7wOw\nHcCwtfY4E0Sz7s9fA3g/gONZJ32naB4WwL3GmJ8YY66r/63Z96VpVPbeuIfp6cFPBowx7QDuBvAH\n1lqR7tWsuVhrI2vt+ai9cS8CcOYJvvKCwxhzFYBBa+1PTjj45ONSa+2FqKmi1xtjXsmdTbovz4vK\n/rmgmRt/HwDmyuqv/+1UYUb04C80jDEp1Db97dbab57KuQCAtXYYwEOoidTdxsSlf5pxf14B4E3G\nmJ0A7kRN3P/cKZgHrLX76v8PAvg31H4Mm31fnheV/XNBMzf+YwBW1C22aQBvA3BPE8+vcQ+Aa+rt\na1DTt08qTI23+ksANllrP3Oq5mKMmW2M6a63c6jZGTah9gPw1mbNw1p7k7W231q7FLXn4UFr7a82\nex7GmDZjTMfxNoDXAViPJt8Xa+0BAHuMMcdL0b0GwMaTMo+TbTRRRoorATyDmj75oSae96sABgBU\nUPtVvRY1XfIBAFsB3I9aXYCTPY9LURPTnkatHuGT9TVp6lwAnAvgifo81gP40/rfTwPwKIBtAL4O\nINPEe3QZgO+einnUz/dU/d+G48/mKXpGzgewtn5vvgWg52TMw0fueXi0ILxxz8OjBeE3vodHC8Jv\nfA+PFoTf+B4eLQi/8T08WhB+43t4tCD8xvfwaEH4je/h0YL4/zPtRhcRj3PfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6c06796050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_DEBUG = True\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def _log(message):\n",
    "    if _DEBUG:\n",
    "        print(message)\n",
    "\n",
    "\n",
    "class ImageProcess(object):\n",
    "\n",
    "    cap = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "\n",
    "        # change input frame buffer size to 640x480\n",
    "        # http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
    "        self.cap.set(3, 640)\n",
    "        self.cap.set(4, 480)\n",
    "\n",
    "    def __destroy__(self):\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def processVideo(self, toGray=False, toShape=[64., 64.]):\n",
    "        ret, frame = self.cap.read()\n",
    "\n",
    "        if toGray:\n",
    "            frame = cv2.cvtColor(frame,\n",
    "                                cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        h_sf = toShape[0] / img.shape[0]\n",
    "        w_sf = toShape[1] / img.shape[1]\n",
    "        frame_rescaled = cv2.resize(frame,\n",
    "                                   None,\n",
    "                                   fx=w_sf,\n",
    "                                   fy=h_sf,\n",
    "                                   interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        if False:\n",
    "            cv2.imshow('frame',\n",
    "                       frame_rescaled)\n",
    "\n",
    "            cv2.waitKey(0)\n",
    "\n",
    "        return frame_rescaled\n",
    "\n",
    "\n",
    "    def processImage(self, fname, toGray=False, toShape = [64., 64.]):\n",
    "\n",
    "        _log(\"%s is loading...\" % fname)\n",
    "        # Load an color image\n",
    "        img = cv2.imread(fname, 1)\n",
    "\n",
    "        # Convert color image to grayscale\n",
    "        if toGray:\n",
    "            img = cv2.cvtColor(img,\n",
    "                                cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        h_sf = toShape[0] / img.shape[0]\n",
    "        w_sf = toShape[1] / img.shape[1]\n",
    "        img_scaled = cv2.resize(img,\n",
    "                                 None,\n",
    "                                 fx=w_sf,\n",
    "                                 fy=h_sf,\n",
    "                                 interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        if False:\n",
    "            cv2.imshow('frame',\n",
    "                       img_scaled)\n",
    "\n",
    "            cv2.waitKey(0)\n",
    "\n",
    "        return img_scaled\n",
    "\n",
    "\n",
    "def main():\n",
    "    ip = ImageProcess()\n",
    "    # ip.captureVideo()\n",
    "    _log('testring for real dataset...')\n",
    "    fname_list = [\n",
    "        os.path.join('./KR_data', 'IMG_20170315_201204260.jpg'),\n",
    "        os.path.join('./KR_data', 'IMG_20170315_201212453.jpg'),\n",
    "        os.path.join('./KR_data', 'IMG_20170315_201232407_BURST000_COVER_TOP.jpg'),\n",
    "        os.path.join('./KR_data', 'IMG_20170315_201232407_BURST001.jpg'),\n",
    "        os.path.join('./KR_data', 'IMG_20170315_203000566.jpg'),\n",
    "    ]    \n",
    "    \n",
    "    for fname in fname_list:\n",
    "        img = ip.processImage(fname)\n",
    "        plt.imshow(img)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Question 7\n",
    "_Choose five candidate images of numbers you took from around you and provide them in the report. Are there any particular qualities of the image(s) that might make classification difficult?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the images taken from the actual surroundings to carry out the test with the learned contents, but the predicted results were not so good.\n",
    "\n",
    "I think the reason why the forecast is not so good is that the actual data is not composed solely of numerical information.\n",
    "\n",
    "In fact, the results of the MNIST synthetic test set are not so good, so I think we need to solve this and worry a bit more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Question 8\n",
    "_Is your model able to perform equally well on captured pictures or a live camera stream when compared to testing on the realistic dataset?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is not. Looking at the prediction results of the actual data, it seems that the input image is different but most of them predict the similar value. I think there is a problem in CNN somewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Optional: Question 9\n",
    "_If necessary, provide documentation for how an interface was built for your model to load and classify newly-acquired images._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Answer:** Leave blank if you did not complete this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "----\n",
    "### Step 4: Explore an Improvement for a Model\n",
    "\n",
    "There are many things you can do once you have the basic classifier in place. One example would be to also localize where the numbers are on the image. The SVHN dataset provides bounding boxes that you can tune to train a localizer. Train a regression loss to the coordinates of the bounding box, and then test it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Question 10\n",
    "_How well does your model localize numbers on the testing set from the realistic dataset? Do your classification results change at all with localization included?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Question 11\n",
    "_Test the localization function on the images you captured in **Step 3**. Does the model accurately calculate a bounding box for the numbers in the images you found? If you did not use a graphical interface, you may need to investigate the bounding boxes by hand._ Provide an example of the localization created on a captured image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "----\n",
    "## Optional Step 5: Build an Application or Program for a Model\n",
    "Take your project one step further. If you're interested, look to build an Android application or even a more robust Python program that can interface with input images and display the classified numbers and even the bounding boxes. You can for example try to build an augmented reality app by overlaying your answer on the image like the [Word Lens](https://en.wikipedia.org/wiki/Word_Lens) app does.\n",
    "\n",
    "Loading a TensorFlow model into a camera app on Android is demonstrated in the [TensorFlow Android demo app](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android), which you can simply modify.\n",
    "\n",
    "If you decide to explore this optional route, be sure to document your interface and implementation, along with significant results you find. You can see the additional rubric items that you could be evaluated on by [following this link](https://review.udacity.com/#!/rubrics/413/view)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Optional Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your optional code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Documentation\n",
    "Provide additional documentation sufficient for detailing the implementation of the Android application or Python program for visualizing the classification of numbers in images. It should be clear how the program or application works. Demonstrations should be provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "_Write your documentation here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \n",
    "**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "name": "digit_recognition.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
